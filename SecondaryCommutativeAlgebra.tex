\documentclass[12pt]{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{units}
\usepackage{graphicx}
\usepackage{tikz-cd}
\usepackage{nicefrac}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{color}
\usepackage{tensor}
\usepackage{tipa}
\usepackage{bussproofs}
\usepackage{ stmaryrd }
\usepackage{ textcomp }
\usepackage{leftidx}
\usepackage{afterpage}
\usepackage{varwidth}
\usepackage{physics}

\newcommand\blankpage{
	\null
	\thispagestyle{empty}
	\addtocounter{page}{-1}
	\newpage
}

\graphicspath{ {images/} }

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[subsection] % reset theorem numbering for each chapter
\newtheorem{proposition}[thm]{Proposition}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{fact}[thm]{Fact}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition} % definition numbers are dependent on theorem numbers
\newtheorem{exmp}[thm]{Example} % same for example numbers
\newtheorem{notation}[thm]{Notation}
\newtheorem{remark}[thm]{Remark}
\newtheorem{condition}[thm]{Condition}
\newtheorem{question}[thm]{Question}
\newtheorem{construction}[thm]{Construction}
\newtheorem{exercise}[thm]{Exercise}
\newtheorem{example}[thm]{Example}
\newtheorem{observation}[thm]{Observation}

\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\scr}[1]{\mathscr{#1}}
\newcommand{\call}[1]{\mathcal{#1}}
\newcommand{\psheaf}{\text{\underline{Set}}^{\scr{C}^{\text{op}}}}
\newcommand{\und}[1]{\underline{\hspace{#1 cm}}}
\newcommand{\adj}[1]{\text{\textopencorner}{#1}\text{\textcorner}}
\newcommand{\comment}[1]{}
\newcommand{\lto}{\longrightarrow}

\usepackage[margin=1.5cm]{geometry}

\title{Secondary commutative algebra}
\author{Will Troiani}
\date{August 2020}

\begin{document}
	\maketitle
	\tableofcontents

\section{Graded rings, modules, and algebras}\label{Sec:Graded}
\subsection{General Theory}
\begin{defn}
	Let $G$ be a totally ordered group. A \textbf{$G$-graded ring} is a ring $A$ along with a \textbf{$G$-grading}, ie, a group isomorphism
	\begin{equation}
		A \cong \bigoplus_{g \in G}A_g
	\end{equation}
	for some collection of subgroups $\lbrace A_g \subseteq A \rbrace_{g \in G}$. Furthermore, $A$ is required to be such that $A_gA_h \subseteq A_{g + h}$ for all $g,h \in G$.
	
	An element $a \in A$ such that $a \in A_g$ is \textbf{homogeneous of degree $g$}. An ideal which can be generated by homogeneous elements is a \textbf{homogeneous ideal}.
	
	Let $A$ be a $G$-graded ring, a \textbf{$G$-graded $A$-module} $M$ is an $A$-module along with a \textbf{$G$-grading}, ie a group isomorphism
	\begin{equation}
		M \cong \bigoplus_{g \in G} M_g
	\end{equation}
	for some collection of subgroups $\lbrace M_g \subseteq M\rbrace_{g \in G}$. Furthermore, $M$ is required to be such that $A_gM_h \subseteq M_{g + h}$ for all $g,h \in G$.
\end{defn}
\begin{fact}
	An ideal $I$ is homogeneous if and only if
	\begin{equation}
		I = \bigoplus_{g \in G}(A_g \cap I)
	\end{equation}
\end{fact}
\begin{example}
	The canonical example is a polynomial ring $k[x_1,...,x_n]$ which is $\bb{Z}$-graded. The subgroup of degree $m$ elements is generated by all degree $m$ monomials.
	
	This ring also admits a $\bb{Z}^n$-grading, where the subgroup of degree $(m_1,...,m_n)$ elements is generated by the polynomial $x^{m_1}_1...x^{m_n}_n$.
\end{example}
\begin{example}\label{ex:quotient_of_homog_by_homog}
	If $A \cong \bigoplus_{g \in G}A_g$ is a graded algebra and $I \subseteq A$ is a homogeneous ideal, then $A/I$ is graded as per:
	\begin{equation}
		A/I \cong \bigoplus_{g \in G}A_g/\bigoplus_{g \in G}(A_g \cap I) \cong \bigoplus_{g \in G}A_g/A_g \cap I
	\end{equation}
\end{example}

The most important case will be when $G = \bb{Z}$, we now focus on this case (although there is no particular reason have to, other than commutativity sakes).
\begin{defn}\label{def:hom_tens_grading}
	Let $A$ be a $\bb{Z}$-graded ring and $M,N$ two $\bb{Z}$-graded $A$-modules. A \textbf{morphism of $\bb{Z}$-graded $A$-modules of degree $i (\in \bb{Z})$} is an $A$-module homomorphism $\varphi: A \lto B$ subject to
	\begin{equation}
		\forall j \in \bb{Z}, f(A_j) \subseteq B_{j + i}
	\end{equation}
	we denote the $A$-module of such morphisms by $\operatorname{Hom}(A,B)$.
	
	This gives rise to a $\bb{Z}$-graded module
	\begin{equation}
		\operatorname{Hom}(A,B) := \bigoplus_{i \in \bb{Z}}\operatorname{Hom}(A,B)_i
	\end{equation}
	Moreover, the tensor product is naturally a $\bb{Z}$-graded module with grading:
	\begin{equation}
		A \otimes B \cong \bigoplus_{\substack{i \in \bb{Z}\\ n + m = i}}A_n \otimes B_m
	\end{equation}
\end{defn}
What if $A,B$ are $\bb{Z}$-graded \emph{algebras}? All the definitions go through as expected except for the tensor product which has multiplication defined by
\begin{equation}\label{eq:tensor}
	(a_1 \otimes b_1)(a_2 \otimes b_2) = (-1)^{\operatorname{deg}a_2\operatorname{deg}b_1}(a_1a_2 \otimes b_1b_2)
\end{equation}
This multiplication law is necessary for the differential cases in order to make $\operatorname{Hom}(A,B) \otimes A \lto B$ given on pure tensors by $f \otimes a \longmapsto f(a)$ a morphism of chain complexes, a statement we now explain.
\begin{defn}\label{def:diff_graded}
	Let $A$ be a ring, a \textbf{differential, $\bb{Z}$-graded $A$-module} is a $\bb{Z}$-graded $A$-module $M$ along with a \textbf{differential}, ie, a linear map $d: A \lto A$ such that
	\begin{equation}
		\forall m \in \bb{Z}, \forall m \in M, \operatorname{deg}f(m) = \operatorname{deg}m - 1
	\end{equation}
	A \textbf{morphism of differential, $\bb{Z}$-graded $A$-modules} $M,N$ is a morphism of $\bb{Z}$-graded modules $\varphi: M \lto N$ such that for all $i \in \bb{Z}$
	the following diagram commutes:
	\begin{equation}
		\begin{tikzcd}
			M_i\arrow[r, "\varphi"]\arrow[d,"{d_M}"] & N_i\arrow[d,"{d_N}"]\\
			M_{i - 1}\arrow[r,"{\varphi}"] & N_{i - 1}
		\end{tikzcd}
	\end{equation}
\end{defn}
We often say ``graded" in place of $\bb{Z}$-graded.

In accordance with Definition \ref{def:diff_graded}, every differential, graded module is naturally a chain complex.
\begin{defn}
	Let $(A,d_A),(B,d_B)$ be differential, graded $k$-algebras (for some commutative ring $k$), the tensor product is naturally equipped with the following differential:
	\begin{equation}
		d_{A \otimes B}(a \otimes b) = d_A(a) \otimes b + (-1)^{\operatorname{deg}a}a \otimes d_B(b)
	\end{equation}
	Similarly, $\operatorname{Hom}(A,B)$ is naturally equipped with the following differential:
	\begin{equation}
		d_{H}(f)= d_B(f) - (-1)^{\operatorname{deg}f}f(d_A)
	\end{equation}	
	
\end{defn}
\begin{remark}\label{rmk:useless}
	Let $\psi: \operatorname{Hom}(A,B) \otimes A \lto B$ be the evaluation map, ie, the map given on pure tensors by $\psi(f\otimes a) = f(a)$. We claim this is a chain map. We require commutativity of the following diagram:
	\begin{equation}
		\begin{tikzcd}
			(\operatorname{Hom}(A,B) \otimes A)_n\arrow[r,"{\psi}"]\arrow[d,"{d_{H\otimes A}}"] & B_n\arrow[d,"{d_B}"]\\
			(\operatorname{Hom}(A,B) \otimes A)_{n-1}\arrow[r,"{\psi}"] & B_{n-1}
		\end{tikzcd}
	\end{equation}
	Unpacking definitions, for all pure tensors $f \otimes a \in (\operatorname{Hom}(A,B) \otimes A)_n$ we have
	\begin{equation}
		d_B(\psi)(f \otimes a) = d_B(f(a))
	\end{equation}
	and
	\begin{align*}
		\psi d_{H\otimes A}(f\otimes a) &= \psi (d_Hf \otimes a + (-1)^{\operatorname{deg}f}f \otimes d_A(a))\\
		&= d_Hf(a) + (-1)^{\operatorname{deg}f}f(d_A(a))\\
		&= d_B(f(a)) - (-1)^{\operatorname{deg}f}f(d_A(a)) + (-1)^{\operatorname{deg}f}f(d_A(a))\\
		&= d_B(f(a))
	\end{align*}
	so indeed we have a morphism of differential, graded algebras.
\end{remark}
\begin{remark}
	Notice that Remark \ref{rmk:useless} only explains why we put a minus sign in $d_H$ and absolutely nothing else.
\end{remark}

Consider the $\bb{Z}$-graded ring $S := k[x_0,...,x_n]$. We can define a ring homomorphism $\varphi: S \lto S$ given by multiplication by $x_0$, strictly speaking though this fails to be a morphism of $\bb{Z}$-graded rings as, for example, the degree $0$ element $1$ is mapped to the degree $1$ element $x_0$.

There is an obvious fix to this, we simply shift the grading of the first copy of $S$, to this end we define:
\begin{defn}
	Let $A$ be a $G$-graded ring. We denote by $A(g)$ the graded ring which is identical as a ring to $A$, but with the grading shifted by $g$, more concretely, if for an arbitrary $G$-graded ring $B$ we denote by $B_g$ the subgroup generated by the degree $g$ elements, then we have
	\begin{equation}
		A(g)_h = A_{g + h}
	\end{equation}
	In the special case where $G = \bb{Z}$, the differential denoted $d_{A(n)}$ is given by $d_{A(n)}(a) = (-1)^nd_A(a)$.
\end{defn}
\begin{example}
	We have a well defined morphism of graded rings
	\begin{equation}
		S(-1) \stackrel{(x_0)}{\lto}S
	\end{equation}
\end{example}
We conclude this Section with one last chain complex constructor: let $M$ be an $R$-module and $y \in R$ an arbitrary element of $R$.  Let $\scr{G}$ be a chain complex, we denote by $K(y)$ (see Definition \ref{def:koszul_complex} for a justification of this choice of notation) the following chain complex:
\begin{equation}
	0 \lto R \stackrel{y}{\lto} R \lto 0
\end{equation}
We define:
\begin{defn}
	The \textbf{mapping cone} of multiplication $\scr{G} \stackrel{y}{\lto} \scr{G}$ is the tensor product:
	\begin{equation}
		K(y) \otimes \scr{G}
	\end{equation}
\end{defn}
The usefulness of the mapping cone comes from the following property:
\begin{proposition}\label{prop:mapping_exact_sequence}
	Let $\scr{G}$ be a chain complex of $R$-modules and let $y\in R$ be an arbitrary element of $R$. Then there exists a long exact sequence of homology groups:
	\begin{equation}\label{eq:mapping_exact_sequence}
		\hdots \lto H_{i-1}(\scr{G}) \stackrel{y}{\lto} H_{i-1}(\scr{G}) \lto H_{i}(K(y) \otimes \scr{G})\lto H_i(\scr{G}) \stackrel{y}{\lto} H_{i}(\scr{G}) \lto \hdots
	\end{equation}
	where the connecting morphisms are multiplication by $y$.
\end{proposition}
\begin{proof}
	Construct the following short exact sequence of chain complexes:
	\begin{equation}
		\begin{tikzcd}
			R(-1)\arrow[d] & 0\arrow[r]\arrow[d] & 0\arrow[r]\arrow[d] & R\arrow[r]\arrow[d] & 0\arrow[d]\\
			K(y)\arrow[d] & 0\arrow[r]\arrow[d] & R\arrow[r,"{y}"]\arrow[d] & R\arrow[r]\arrow[d] & 0\arrow[d]\\
			R &0\arrow[r] & R\arrow[r] & 0\arrow[r] & 0
		\end{tikzcd}
	\end{equation}
	We can tensor this entire diagram with $\scr{G}$ to obtain the following short exact sequence:
	\begin{equation}
		\begin{tikzcd}
			\scr{G}(-1)\arrow[d] & \hdots\arrow[r] & G_{i-2}\arrow[r]\arrow[d] & G_{i-1}\arrow[r]\arrow[d] & G_i\arrow[r]\arrow[d] & \hdots\\
			K(y)\otimes \scr{G}\arrow[d] & \hdots\arrow[r] & G_{i-2} \oplus G_{i-1}\arrow[r]\arrow[d] & G_{i-1} \oplus G_i\arrow[r]\arrow[d]\arrow[r] & G_{i} \oplus G_{i+1}\arrow[r]\arrow[d] & \hdots\\
			\scr{G} & \hdots\arrow[r] & G_{i-1}\arrow[r] & G_i\arrow[r] & G_{i+1}\arrow[r] & \hdots
		\end{tikzcd}
	\end{equation}
	which induces the exact sequence \eqref{eq:mapping_exact_sequence}.
\end{proof}

\subsection{Exterior algebra}
Throughout, $R$ is a commutative ring with unit and $M$ a left $R$-module.
\begin{defn}
	The \textbf{exterior algebra} associated to $M$ is the pair $(\bigwedge M, \iota: M \lto \bigwedge M)$ satisfying the following universal property: if $N$ is an $R$-algebra, and $f: M \lto N$ is an $R$-module homomorphism such that for all $m \in M, f(m)^2 = 0$ then there exists a unique $R$-algebra homomorphism $g: \bigwedge M \lto N$ making the following diagram commute:
	\begin{equation}
		\begin{tikzcd}
			M\arrow[r,"{\iota}"]\arrow[dr,swap,"{f}"] & \bigwedge M\arrow[d,"g"]\\
			& N
		\end{tikzcd}
	\end{equation}
	Moreover, if $N$ is graded and $f(M) \subseteq N_1$ then $g$ is a morphism of graded modules.
\end{defn}
\begin{remark}\label{rmk:existence_wedge}
	Existence of the exterior algebra is given by taking $\bigwedge M$ to be, where $m$ ranges over all $m \in M$:
	\begin{equation}
		\bigwedge M := \bigotimes M/m \otimes m
	\end{equation}
\end{remark}
\begin{remark}
	If $M$ is free and of finite rank, and $v_1,...,v_n$ is a basis for $M$, then a basis for $\bigwedge M$ as a vector space is given by
	\begin{equation}
		\lbrace v_{i_1} \wedge \hdots \wedge v_{i_d} \mid 1 \leq d \leq n, 1 \leq i_1 < \hdots < i_d \leq n\rbrace
	\end{equation}
	which is a set of size $2^n$.
\end{remark}
\begin{proposition}\label{prop:wedge_morphism}
	Let $\varphi: M \lto N$ be an $R$-module homomorphism. Then there exists a unique morphism $\wedge \varphi: \wedge M \lto \wedge N$ such that the following diagram commutes:
	\begin{equation}
		\begin{tikzcd}
			M\arrow[r,"{\varphi}"]\arrow[d] & N\arrow[d]\\
			\wedge M\arrow[r,"{\wedge \varphi}"] & \wedge N
		\end{tikzcd}
	\end{equation}
\end{proposition}
\begin{defn}
	As per Example \ref{ex:quotient_of_homog_by_homog} we have that the exterior algebra is $\bb{Z}$-graded. We denote the degree $d$ elements of $\bigwedge M$ by $\bigwedge^d M$.
\end{defn}
There are two canonical operators on the exterior algebra, which we now explain.
\begin{defn}
	Let $x \in \bigwedge M$ be an arbitrary element. We define
	\begin{align*}
		x \wedge \und{0.2}: \bigwedge M &\lto \bigwedge M\\
		x_1 \wedge \hdots \wedge x_n &\longmapsto x \wedge x_1 \wedge \hdots \wedge x_n
	\end{align*}
\end{defn}
The second map is a bit harder to explain. We begin with some preliminary observations.
\begin{lemma}
	Let $M$ be free and of finite rank. Then
	\begin{equation}
		\bigwedge^d M^{\ast} \cong (\bigwedge^d M)^\ast
	\end{equation}
\end{lemma}
\begin{proof}
	Let $\lambda_1,...,\lambda_n$ be elements of $M^\ast$. Define the following functional:
	\begin{align*}
		M^d &\lto R\\
		(m_1,...,m_d) &\longmapsto \operatorname{det}\big((\lambda_i m_j)_{ij}\big)
	\end{align*}
	This indeed is bilinear and so induces a map $M^{\otimes d} \lto R$ and moreover is such that any pure tensor with repeated elements maps to $0$, thus we obtain a map
	\begin{equation}
		\bigwedge M \lto R
	\end{equation}
	We have thus described a homomorphism $M^{\ast d} \lto R$ which indeed is bilinear and maps tuples with repeated elements to $0$, thus we have described a function
	\begin{equation}
		\varphi: \bigwedge^d M^{\ast} \lto \big(\bigwedge^d M\big)^{\ast}
	\end{equation}
	It remains to show that this is an isomorphism, and for this we use for the first time that $M$ is free of finite rank. Let $v_{i_1},...,v_{i_d} \in M$ be a basis. One can show
	\begin{equation}
		\varphi(v_{i_1} \wedge \hdots \wedge v_{i_d}) = (v_{i_1} \wedge \hdots \wedge v_{i_d})^{\ast}
	\end{equation}
	and so $\varphi$ maps onto a basis for $\big(\bigwedge^d M\big)^\ast$ so in particular $\varphi$ is surjective. Since $\varphi$ is a surjective map between vector spaces of the same, finite dimension, it must therefore also be injective.
\end{proof}
\begin{remark}
	Another simple but important observation is that $\bigwedge^d \und{0.2}$ is a functor.
\end{remark}
We can now define the second canonical map.
\begin{defn}
	Assume that $M$ is free of finite rank. Let $\eta \in M^\ast$. There is the following sequence of compositions
	\begin{equation}\label{eq:contraction}
		\begin{tikzcd}
			{\bigwedge^d M}\arrow[r] & {\bigwedge^d M^{\ast\ast}}\arrow[r] & {\big(\bigwedge^d M^\ast\big)^\ast}\arrow[d,"{(\eta \wedge \und{0.2})^\ast}"]\\
			{\bigwedge^{d-1} M} & {\bigwedge^{d-1}M^{\ast\ast}}\arrow[l]& {\big(\bigwedge^{d-1} M^\ast\big)^{\ast}}\arrow[l]
		\end{tikzcd}
	\end{equation}
	The resulting map $\bigwedge^d M \lto \bigwedge^{d-1}M$ is \textbf{contraction} and is denoted by $\eta \lrcorner$.
	
	For an element $x \in M$ we often denote $x \wedge \und{0.2}$ by $x$ and $x^\ast \lrcorner$ by $x^\ast$.
\end{defn}
\begin{remark}
	We can follow the sequence of homomorphism \eqref{eq:contraction} to obtain an explicit formula for the contraction map. To this end, let $v_1,...,v_n$ be a basis for $M$ and observe the following calculation:
	\begin{align*}
		v_{i_1} \wedge \hdots \wedge v_{i_d} &\longmapsto v_{i_1}^{\ast\ast} \wedge \hdots \wedge v_{i_d}^{\ast\ast}\\
		&\longmapsto (v_{i_1}^\ast \wedge \hdots \wedge v_{i_d}^\ast)^\ast\\
		&\longmapsto (v_{i_1}^\ast \wedge \hdots \wedge v_{i_d}^\ast)^\ast\circ(\eta \wedge \und{0.2})
	\end{align*}
	We then have for any basis vector $(v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast)^\ast \in (\bigwedge^{d-1}M^\ast)^\ast$ that
	\begin{align}
		(v_{i_1}^\ast \wedge \hdots \wedge v_{i_d}^\ast)^\ast&\circ(\eta \wedge \und{0.2})(v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast)\\
		\label{eq:dual_half_way}&= (v_{i_1}^\ast \wedge \hdots \wedge v_{i_d}^\ast)^\ast(\eta \wedge v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast)
	\end{align}
	By writing $\eta = \eta(v_1)v_1^\ast + \hdots + \eta(v_n)v_n^\ast$ we have
	\begin{align*}
		\eta \wedge v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast &= (\eta(v_1)v_1^\ast+ \hdots + \eta(v_n)v_n^\ast)\wedge v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast\\
		&= \sum_{k = 1}^n \eta(v_k)v_k^\ast \wedge v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast
	\end{align*}
	so returning to \eqref{eq:dual_half_way}, we have
	\begin{align*}
		(v_{i_1}^\ast \wedge \hdots \wedge v_{i_d}^\ast)^\ast(\sum_{k = 1}^n \eta(v_k)v_k^\ast \wedge v_{j_1}^\ast \wedge \hdots \wedge v_{j_{d-1}}^\ast)
	\end{align*}
	which, if there exists $l \in \lbrace 1,...,d\rbrace$ such that $(i_1,...,i_{\hat{l}},...,i_d) = (j_1,...,j_{d-1})$ is equal to $(-1)^{l-1}\eta(v_{i_l})$. Hence, traversing the other direction of \eqref{eq:contraction} we see that this corresponds to the element
	\begin{equation}
		\eta_{\lrcorner}(v_{i_1} \wedge \hdots \wedge v_{i_d}) = \sum_{j = 1}^d(-1)^{j-1} \eta(v_{i_j}) v_{i_1} \wedge \hdots \wedge \hat{v_{i_j}} \wedge \hdots \wedge v_{i_d}
	\end{equation}
\end{remark}
\begin{remark}\label{rmk:contraction_differential}
	Notice that from \eqref{eq:contraction} and the fact that $\eta \wedge \eta \wedge \und{0.2} = 0$ it follows that contraction is a differential. Thus there is a chain complex
	\begin{equation}
		L(M) := \hdots \wedge^2 M \stackrel{\eta\lrcorner}{\lto} M \stackrel{\eta}{\lto} R \lto 0
	\end{equation}
\end{remark}
In fact, more can be said, we return to this after considering some category theoretic facts about the exterior algebra.
\subsubsection{Category theoretic properties of the exterior algebra}
The exterior algebra admits some properties which are described well using the language of category theory.
\begin{defn}
	A \textbf{super algebra} is a graded, commutative algebra $A$ with the following properties:
	\begin{itemize}
		\item for all $a,b \in A$ we have $ab = (-1)^{\operatorname{deg}a\operatorname{deg}b}ba$,
		\item if $a \in A$ is homogeneous of odd degree, then $a^2 = 0$.
	\end{itemize}
\end{defn}
\begin{example}
	The exterior algebra $\bigwedge M$ of a module $M$ is a super algebra.
\end{example}
\begin{observation}
	The wedge product $\wedge(\und{0.2})$ is a functor. This follows from Remark \ref{rmk:existence_wedge} and Proposition \ref{prop:wedge_morphism}.
\end{observation}
\begin{notation}
	We let $\text{mod}_R$ denote the category of commutative, left $R$-modules, and $\text{sAlg}_R$ the category of $R$-super algebras.
	
	We denote by $(\und{0.2})_1: \text{sAlg}_R \lto \text{mod}_R$ the functor which takes a super algebra to its degree $1$ component.
\end{notation}
\begin{observation}\label{obs:wedge_adjunction}
	The functor $\wedge(\und{0.2})$ is left adjoint to $(\und{0.2})_1$. This follows from Proposition \ref{prop:wedge_morphism}.
\end{observation}
We now use these observations to prove that there is a canonical isomorphism $\wedge(M) \otimes \wedge(N) \lto \wedge(M \oplus N)$.
\begin{proposition}\label{prop:sum_tensor_wedge}
	For any pair of $R$-algebras $M,N$ there is an isomorphism
	\begin{align*}
		\Psi: \wedge ( M \oplus N ) &\lto \wedge M \otimes \wedge N\\
		\psi(m, n) &= m \otimes 1 + 1 \otimes n
	\end{align*}
\end{proposition}
\begin{proof}
	By Observation \ref{obs:wedge_adjunction} and that the tensor product acts as a coproduct in the category of $\text{Alg}_R$ of commutative $R$-algebras, we have the following commutative diagram, where the horizontal arrows are composition and all vertical arrows are natural isomorphisms, note also we simply write $H$ in place of $\operatorname{Hom}$:
	\begin{equation}
		\begin{tikzcd}
			H(\wedge(M \oplus N), \wedge M \otimes \wedge N) \times H(\wedge M \otimes \wedge N, \wedge(M \oplus N))\arrow[r]\arrow[d] & H(\wedge(M \oplus N), \wedge(M \oplus N))\arrow[ddd]\\
			H(M \oplus N, (\wedge M \otimes \wedge N)_1) \times H(\wedge M, \wedge(M \oplus N)) \times H(\wedge N, \wedge(M \oplus N))\arrow[d]\\
			H(M \oplus N, M \oplus N) \times H(M, M\oplus N) \times H(N, M \oplus N)\arrow[d]\\
			H(M \oplus N, M \oplus N) \times H(M \oplus N, M \oplus N)\arrow[r] & H(M \oplus N, M \oplus N)
		\end{tikzcd}
	\end{equation}
	Since the image of $\operatorname{id}_{M \oplus N}$ under
	\begin{equation}
		H(M \oplus N, M \oplus N) \times H(M \oplus N, M \oplus N)\lto H(M \oplus N, M \oplus N) \lto H(\wedge(M \oplus N), \wedge(M \oplus N))
	\end{equation}
	is $\operatorname{id}_{\wedge(M \oplus N)}$ it follows that there are canonical morphisms $\psi: \wedge(M \oplus N) \lto \wedge M \otimes \wedge N$ and $\psi': \wedge M \otimes \wedge N \lto \wedge (M \oplus N)$ such that $\psi' \psi = \operatorname{id}_{\wedge(M \oplus N)}$. A similar argument shows $\psi \psi' = \operatorname{id}_{\wedge M \otimes \wedge N}$.
\end{proof}
\section{Regular and quasi-regular sequences}
This Section requires Section \ref{Sec:Graded} as a prerequisite.
\subsection{Regular sequences and the Koszul complex}
Throughout, all rings are commutative, associative, and unital.
\begin{defn}\label{def:regular_sequence}
	Let $M$ be a left $R$-module. A sequence $(x_1,...,x_n)$ where each $x_i \in R$ is \textbf{regular} if
	\begin{itemize}
		\item for all $i = 1,...,n$ the element $f_i$ is a nonzerodivisor of $M/(x_1,...,x_{i-1})M$
		\item the module $M/(x_1,...,x_n)M$ is non-zero.
	\end{itemize}
\end{defn}
For now we focus on regular sequences of a \emph{ring}, which of course obeys the same definition as \ref{def:regular_sequence} where the ring is considered as a module over itself.
\begin{example}
	Let $k$ be a field, the sequence $(x,y(1-x),z(1-x))$ is regular in $k[x,y,z]$
\end{example}
\begin{proof}
	\begin{itemize}
		\item $x$ is clearly a nonzerodivisor of $k[x,y,z]$.
		\item Say $m \in k[x,y,z]/(x)$ satisfied $m(y(1-x)) = 0$, then $y$ is a zero divisor in $k[x,y,z]/(x) \cong k[y,z]$ which is a contradiction.
		\item A similar argument shows that $z(1-x)$ is not a zero divisor of $k[x,y,z]/(x,y)$
		\item Lastly, $1 \neq 0 \in k[x,y,z]/(x,y,z)$.
	\end{itemize}
\end{proof}
\begin{remark}
	It is \emph{not} necessarily the case that for a regular sequence $(f_1,...,f_n)$ in a ring $R$, $f_j$ is a non zero divisor of $R/(f_1,...,f_{j-2})$. For instance, the sequence $(x,y)$ is a regular sequence in $k[x,y,w_1,w_2,...]/I$, where $k$ is a field and $I$ is the ideal generated by all $yw_i$ and all $w_i - xw_{i+1}$, even though $y$ is a zero divisor.
\end{remark}
One way of thinking about regular sequences is that they ``cut $R$ down" as much as possible at each stage of modding out. More precisely, if $r$ is a non zero divisor of $R$ then the map $R \to R$ given by multiplication by $r$ is injective. In this sense we ``kill just as much, if not more of $R$" by modding out by $(r)$ than if we had modded out by $(r')$, where $r' \in R$ is a zero divisor.
%
\begin{defn}\label{def:koszul_complex}
	Let $M$ be a left $R$-module and $x \in M$ an element. The \textbf{Koszul complex} $K(x)$ is the following chain complex
	\begin{equation}
		0 \lto R \lto M \lto \wedge^2 M \lto \wedge^3 M \lto \hdots \lto \wedge^n M \stackrel{d_x^n}{\lto} \wedge^{n+1}M \lto \hdots
	\end{equation}
	where $d_x^n: \wedge^n M \lto \wedge^{n+1}M$ is defined by the rule $m \longmapsto x \wedge m$.
	
	In the special case where $M = R^m$ and $x = (x_1,...,x_m)$ we write $K(x_1,...,x_n)$ for $K(x)$.
\end{defn}
\begin{example}\label{ex:K(x,y)}
	Let $M = R^2$ and let $x,y \in R$. Then $K(x,y)$ is the following chain complex:
	\begin{equation}
		0 \lto R \lto R^2 \lto \wedge^2 R^2 \lto \wedge^3 R^2 \lto 0 \lto \hdots
	\end{equation}
	which is such that the following diagram commutes, with vertical arrows isomorphisms
	\begin{equation}
		\begin{tikzcd}[row sep = huge]
			0\arrow[r]\arrow[d] & R\arrow[r,"{d_{(x,y)}^1}"]\arrow[d] & R^2\arrow[r,"{d_{(x,y)}^2}"]\arrow[d] &\wedge^2 R^2\arrow[r,"{d_{(x,y)}^3}"]\arrow[d] & \wedge^3 R^2\arrow[d]\arrow[r] &  \hdots\\
			0\arrow[r] & R\arrow[r,"{\begin{pmatrix}
					x\\
					y
				\end{pmatrix}
			}"] & R^2\arrow[r,"{\begin{pmatrix}
					y \text{  } -x
				\end{pmatrix}
			}"]  & R\arrow[r] & 0\arrow[r] & \hdots
		\end{tikzcd}
	\end{equation}
	so we obtain a simple special case.
	
	Further, in the setting where $M = R$ and $x \in R$, the Koszul complex $K(x)$ is simply multiplication by $x$:
	\begin{equation}
		0 \lto R \stackrel{x}{\lto} R
	\end{equation}
\end{example}
We can use the simple description given in Example \ref{ex:K(x,y)} to solve an exercise:
\begin{exercise}
	Show that if
	\begin{equation}
		M := \begin{pmatrix}
			a & b\\
			c & d
		\end{pmatrix}
	\end{equation}
	is a matrix of elements in $R$ such that $M$ has determinant given by a unit in $R$, then $K(x,y) \cong K(ax + by, cx + dy)$.
\end{exercise}
\begin{proof}
	We construct the following diagram:
	\begin{equation}
		\begin{tikzcd}
			0\arrow[r] & R\arrow[r]\arrow[d,"{\operatorname{id}_R}"] & R \oplus R\arrow[r]\arrow[d,"{M}"] & R\arrow[d,"{\operatorname{det}M}"]\arrow[r] & 0\\
			0\arrow[r] & R\arrow[r] & R \oplus R\arrow[r] & R\arrow[r] & 0
		\end{tikzcd}
	\end{equation}
	which is invertible by the assumptions on $M$.
\end{proof}

\subsection{Koszul Complex and lengths of maximal regular sequences}
We will now relate the homology of the Koszul complex to lengths of maximal regular sequences. In the following we make use of the notation:
\begin{notation}
	For ideals $I,J$, denote:
	\begin{equation}
		(I:J) := \lbrace f \in R \mid fJ \subseteq I\rbrace
	\end{equation}
\end{notation}
\begin{observation}\label{obs:koszul_reg}
	The Koszul complex $K(x,y)$ admits $K(x)$ as a subcomplex, which then pushes forward to a cokernel, yielding the following commutative diagram where the vertical sequences are exact:
	\begin{equation}\label{eq:sub_quotient}
		\begin{tikzcd}[row sep = huge]
			0\arrow[r] & R\arrow[r,"{x}"] & R\arrow[r] & 0\\
			0\arrow[r] & R\arrow[u,"{\operatorname{id}_R}"]\arrow[r,"{\begin{pmatrix}
					x\\
					y
				\end{pmatrix}
			}"] & R \oplus R\arrow[r,"{\begin{pmatrix}
					y \text{  } -x
				\end{pmatrix}
			}"]\arrow[u,"{\pi_2}"] & R\arrow[u]\\
			& 0\arrow[u]\arrow[r] & R\arrow[r,"{-x}"]\arrow[u,"{\iota_1}"] & R\arrow[u,swap,"{\operatorname{id}_R}"]
		\end{tikzcd}
	\end{equation}
	and so we obtain a long exact sequence of homology:
	\begin{equation}
		0\lto H^0(K(x)) \stackrel{\delta}{\lto} H^0(K(x)) \lto H^1(K(x,y)) \lto H^1(K(x))\lto 0
	\end{equation}
	where the connecting morphism $\delta$ is multiplication by $y$ (as can easily be checked).
	
	Notice that if $H^1(K(x,y))=0$ then
	\begin{equation}
		H^0(K(x))/yH^0(K(x)) \cong 0
	\end{equation}
	Under the further assumption that $R$ is a Noetherian local and $y$ is an element of the maximal ideal, we obtain from Nakayama's Lemma that $H^0(K(x)) \cong 0$.
	
	So what is the consequence of this? Since $H^0(K(x)) \cong 0$, we have that $x$ is a nonzerodivisor, as follows straight from the definition. Now we investigate $H^1(K(x,y)) \cong 0$. Since $x$ is a nonzerodivisor, if we have $a,b \in R$ such that $-ax + by = 0$, then $a$ is uniquely determined by $b$, we let $k_a$ denote this $b$. In fact, we obtain an isomorphism
	\begin{align*}
		\gamma: (x:y) &\lto \operatorname{ker}(x\text{ }y)\\
		a &\longmapsto (a,-k_a)
	\end{align*}
	Moreover, the image of $R \lto R \oplus R$ is isomorphic to $(x)$, so we have
	\begin{equation}
		H^1(K(x,y)) \cong (x:y)/(x)
	\end{equation}
	So $H^1K(x,y) \cong 0$ implies $(x:y) = (x)$. In other words, if $f \in R$ is such that $fy \in (x)$ then $f \in (x)$. That is to say that $y$ is a nonzerodivisor of $R/(x)$.
\end{observation}
Thus we have proved (the first part of):
\begin{proposition}\label{prop:Zero_KozHom_reg}
	If $R$ is a Noetherian local ring, and $x,y$ are elements of the maximal ideal, then $H^1(K(x,y)) \cong 0$ if and only if $x,y$ is a regular sequence of $R$.
\end{proposition}
Do regular sequences remain regular if the elements are permuted? In general, no, as Example \ref{ex:permute_reg} shows, but Observation \ref{obs:koszul_reg} can be used to provide a setting where permuting elements of a regular sequence \emph{does} result in a regular sequence (see Proposition \ref{prop:reg_permute}).
\begin{example}\label{ex:permute_reg}
	Consider the ring $R := k[x,y,z]/(xz)$ along with the sequence $(x-1,xy)$. This sequence is regular as $x-1$ is not a zerodivisor of $R$ and $R/(x-1) \cong k[y] \not\cong 0$ inside which $y$ is not a zerodivisor. However, the sequence $(xy, x-1)$ is not regular as $xy$ is a zero divisor in $R$.
\end{example}
\begin{proposition}\label{prop:reg_permute}
	Let $R$ be a Noetherian local ring with maximal ideal $\frak{m}$ and let $(x_1,...,x_n)$ be a regular sequence with each $x_i$ an element of $\frak{m}$. Then any for any permutation $\rho: \lbrace 1,...,n \rbrace \lto \lbrace 1,...,n \rbrace$ the sequence $(x_{\rho(1)},...,x_{\rho(n)})$ is regular.
\end{proposition}
\begin{proof}
	First we prove the case when $n = 2$. We have already seen that the sequence $(x_1,x_2)$ is regular if and only if $H^1(K(x_1,x_2)) \cong 0$ (in the context given by the hypotheses). We then observe the following isomorphism $K(x_1,x_2) \cong K(x_2,x_1)$, where $s: R \oplus R \lto R \oplus R$ is the swap map $s(r_1,r_2) = (r_2,r_1)$.
	\begin{equation}
		\begin{tikzcd}
			0\arrow[r] & R\arrow[r]\arrow[d,"{\operatorname{id}_R}"] & R \oplus R\arrow[r]\arrow[d,"s"] & R\arrow[r]\arrow[d,"{-\operatorname{id}_R}"] & 0\\
			0\arrow[r] & R\arrow[r] & R \oplus R\arrow[r] & R\arrow[r] & 0
		\end{tikzcd}
	\end{equation}
	Now we abstract to the general setting. Let $(x_1,...,x_n)$ be regular, it suffices to show that $(x_1,...,x_{i+1},x_i,..., x_n)$ is regular. In turn, it suffices to show that $x_{i+1},x_i$ is regular in $R/(x_1,...,x_{i-2})$ which then follows from the first part of this proof.
\end{proof}
The Koszul complex can sometimes provide information about when a sequence is regular or not.
\begin{thm}\label{thm:exact_reg}
	Let $M$ be a finitely generated module over a local ring $(R,\frak{m})$. Suppose $x_1,...,x_n \in \frak{m}$. If for some $k$ we have:
	\begin{equation}
		H^k(M \otimes K(x_1,...,x_n)) \cong 0
	\end{equation}
	then
	\begin{equation}
		\forall j \leq k,\quad H^j(M \otimes K(x_1,...,x_n)) \cong 0
	\end{equation}
	Moreover, if $H^{n-1}(M \otimes K(x_1,...,x_n)) \cong 0$ then $(x_1,...,x_n)$ is regular.
\end{thm}
We will need the following Lemma to prove Theorem \ref{thm:exact_reg}.
\begin{lemma}\label{lem:sum_tens}
	Let $N \cong N' \oplus N''$ be a module and $x = (x',x'')$ an element of $N$. We have
	\begin{equation}
		K(x) \cong K(x') \otimes K(x'')
	\end{equation}
\end{lemma}
\begin{proof}
	We have from Proposition \ref{prop:sum_tensor_wedge} that there exists an isomorphism of graded algebras $\wedge N \cong \wedge N' \otimes \wedge N''$, hence it suffices to check commutativity of the following diagram, in what follows we write $\Psi^n$ for the homomorphism $\Psi$ restricted to $\wedge^n N$.
	\begin{equation}
		\begin{tikzcd}
			\hdots\arrow[r] & \wedge^n N\arrow[r]\arrow[d,"{\Psi^n}"] & \wedge^{n+1} N\arrow[r]\arrow[d,"{\Psi^{n+1}}"] & \hdots\\
			\hdots\arrow[r] & (\wedge N' \otimes \wedge N'')^{n}\arrow[r] & (\wedge N' \otimes \wedge N'')^{n+1}\arrow[r] & \hdots 
		\end{tikzcd}
	\end{equation}
	To check commutativity of this, we consider an arbitrary element $y \in \wedge N$ which maps under $\Psi$ to a pure tensor $y_1 \otimes y_2$, indeed it suffices to consider such elements. We calculate:
	\begin{align*}
		x \wedge y &\longmapsto (x_1 \otimes 1 + 1 \otimes x_2) \wedge (y_1 \otimes y_2)\\
		&= x_1 \wedge y_1 \otimes y_2 + (-1)^{y_1}y_1 \otimes x_2 \wedge y_2
	\end{align*}
	On the other hand, we have
	\begin{align*}
		(d_{x_1} \otimes d_{x_2})(y_1 \otimes y_2) &= d_{x_1}(y_1) \otimes y_2 + (-1)^{y_2}y_1 \otimes d_{x_2}(y_2)\\
		&= x_1 \wedge y_1 \otimes y_2 + (-1)^{y_1}y_1 \otimes x_2 \wedge y_2
	\end{align*}
	The result follows.
\end{proof}
\begin{remark}\label{rmk:where_mult}
	We touch on a subtle point. Notice that Definition \ref{def:koszul_complex} defined the Koszul complex in a general setting where the differential is given by multiplication by an element of the \emph{module} $M$ (as apposed to multiplication by an element of the \emph{ring} $R$). We wish to relate the Koszul complex $K(x_1,...,x_n)$ to regularity of the sequence $(x_1,...,x_n)$ however in Definition \ref{def:regular_sequence} we required that $x_1,...,x_n$ be elements of $R$. Hence, in order to relate the Koszul complex to regularity of a sequence, we will chiefly be concerned with the special case of the Koszul complex where multiplication is by an element in the \emph{ring} $R$. In this case, for $x \in R$ we have $M \otimes K(x) \cong K(x\cdot 1_R)$ which follows from the isomorphism $R \otimes M \cong M$.
\end{remark}
\begin{remark}\label{rmk:long_exact_sequence}
	Recall that we established in a general setting the existence of a long exact sequence given a chain complex $\scr{G}$ over a ring $R$ along with an element $y \in R$ (Proposition \ref{prop:mapping_exact_sequence}). If $M$ is a module, $x_1,x_2 \in R$, we let $\scr{G}$ be $M \otimes K(x_1)$ and $y = x_2$, we first note that:
	\begin{align*}
		K(x_2) \otimes (M \otimes K(x_1)) &= M \otimes K(x_1,x_2)
	\end{align*}
	and hence we obtain the following long exact sequence.
	\begin{equation}
		0 \lto H^0(M \otimes K(x_1)) \stackrel{x_2}{\lto} H^0(M \otimes K(x_1)) \lto H^1(M \otimes K(x_1,x_2)) \lto 0
	\end{equation}
	In fact, more can be said. Recall the following identity which holds for all $1 \leq m \leq n$.
	\begin{equation}
		{n-1 \choose m} + {n-1 \choose m-1} = {n \choose m}
	\end{equation}
	Hence there exists an isomorphism:
	\begin{equation}
		\wedge^{m}R^{n-1} \oplus \wedge^{m-1}R^{n-1} \cong \wedge^m R^n
	\end{equation}
	which in turn implies the existence of an isomorphism:
	\begin{equation}
		\Psi_m: (M \otimes \wedge^{m}R^{n-1}) \oplus (M \otimes \wedge^{m-1}R^{n-1}) \cong M \otimes \wedge^mR^n
	\end{equation}
	This can be used to show that $K(x_n) \otimes (M \otimes K(x_1,...,x_{n-1})) \cong M \otimes K(x_1,...,x_n)$, simply observe the following isomorphism of chain complexes, where the top row is $M \otimes K(x_1,...,x_n)$ and the bottom row is $K(x_n) \otimes (M \otimes \wedge^{m-1}R^{n-1})$.
	\begin{equation}
		\begin{tikzcd}[column sep = small]
			0\arrow[r] & M\arrow[r]\arrow[d] & M \otimes R^{n}\arrow[r]\arrow[d,"{\psi_1}"] & M \otimes \wedge^2 R^n\arrow[r]\arrow[d,"{\psi_2}"] & \hdots\arrow[r] & M \otimes \wedge^n R^n\arrow[r]\arrow[d,"{\psi_n}"] & 0\\
			0\arrow[r] & M\arrow[r] & M\otimes(R \oplus R^{n-1} )\arrow[r] & M \otimes ( R^{n-1} \oplus \wedge^2 R^{n-1})\arrow[r] & \hdots\arrow[r] & M \otimes (\wedge^{n}R^{n-1} \oplus \wedge^{n-1}R^{n-1})\arrow[r] & 0
		\end{tikzcd}
	\end{equation}
	Again, using Proposition \ref{prop:mapping_exact_sequence} we obtain a long exact sequence.
	\begin{align*}
		\hdots &\lto H^i(M \otimes K(x_1,...,x_{n-1})) \stackrel{x_n}{\lto} H^i(M \otimes K(x_1,...,x_{n-1})) \lto H^{i+1}(M \otimes K(x_1,...,x_n))\\
		&\lto H^{i+1}(M \otimes K(x_1,...,x_{n-1})) \stackrel{x_n}{\lto} \hdots
	\end{align*}
\end{remark}
We are nearly in a position to prove Theorem \ref{thm:exact_reg}, however we need one more result. Proposition \ref{prop:kozology_explicit} writes $H^i(M \otimes K(x_1,...,x_n))$ out in an explicit form. We adopt the following notation, where $I$ is an ideal of $R$ and $M,N$ are $R$-modules:
\begin{equation}
	(N:IM) := \lbrace m \in M \mid Jm \subseteq N\rbrace
\end{equation}
Notice that $(N:IM)$ is itself an $R$-module.
\begin{proposition}\label{prop:kozology_explicit}
	Let $M$ be finitely generated and $(x_1,...,x_n)$ is a regular sequence. Then:
	\begin{equation}\label{eq:explicit}
		H^i(M \otimes K(x_1,...,x_n)) \cong \big((x_1,...,x_i)M:(x_1,...,x_n)\big)/(x_1,...,x_i)M
	\end{equation}
\end{proposition}
\begin{proof}
	We proceed by induction on $n$. The base case, when $n = 2$, is proved in an exactly similar way to what was done in Observation \ref{obs:koszul_reg}. Now we assume that $n > 3$ and the result holds for $n-1$. Consider the following.
	\begin{align*}
		H^i(M \otimes K(x_1,...,x_{n-1})) &\cong \big((x_1,...,x_i)M:(x_1,...,x_{n-1})\big)/(x_1,...,x_i)M\\
		&\cong 0
	\end{align*}
	where the first $\cong$ follows from the inductive hypothesis and the second $\cong$ follows from the fact that $(x_1,...,x_n)$ is a regular sequence. Using the long exact sequence of Remark \ref{rmk:long_exact_sequence} we infer that the kernel of the endomorphism on the following module given by multiplication by $x_n$.
	\begin{equation}
		H^{i}(M \otimes K(x_1,...,x_{n-1}))
	\end{equation}
	is isomorphic to $H^{i}(M \otimes K(x_1,...,x_n))$. We now use the inductive hypothesis to infer that $H^i(M \otimes K(x_1,...,x_n))$ is isomorphic to the kernel of the endomorphism on the following module given by multiplication by $x_n$.
	\begin{equation}
		\big((x_1,...,x_i)M:(x_1,...,x_{n-1})\big)/(x_1,...,x_i)M
	\end{equation}
	The proof is then complete once it is shown that the kernel of this map is isomorphic to the module given in Equation \ref{eq:explicit}. Indeed, an isomorphism is given by the rule $m \longmapsto m$, one checks that the defining conditions of both modules are equivalent.
\end{proof}
\begin{proof}[Proof of Theorem \ref{thm:exact_reg}]
	We proceed by induction on $n$. The base case, that $K(M \otimes K(x_1,x_2)) \cong 0$ implies that $(x_1,x_2)$ is a regular sequence follows exactly similarly to what was shown in Observation \ref{obs:koszul_reg}. Now we proceed with the inductive step, assume that $n >2$ and assume the result holds true for all $2 \leq i < n$. We first consider the endomorphism on $H^{n-1}(M \otimes K(x_1,...,x_{n-1}))$ given by multiplication by $x_n$. Since $H^i(M \otimes K(x_1,...,x_n)) \cong 0$, it follows from the long exact sequence of Remark \ref{rmk:long_exact_sequence} that the endomorphism $x_n$ is surjective. Hence, by Nakayama's Lemma, we have that $H^{n-1}(M \otimes K(x_1,...,x_{n-1})) \cong 0$. By the inductive hypothesis, this implies that $(x_1,...,x_{n-1})$ is a regular sequence, and it remains to show that $x_n$ is not a zero divisor of $M/(x_1,...,x_{n-1})M$.
	
	To do this, we invoke Proposition \ref{prop:kozology_explicit}. Indeed,$(x_1,...,x_n)$ is regular and so:
	\begin{equation}
		\big((x_1,...,x_{n-1})M:(x_1,...,x_n)\big)/(x_1,...,x_i)M \cong 0
	\end{equation}
	completing the proof.
\end{proof}
The following two results are bonus, and are not relevant to the core point of this Section. Indeed, these results are used in \cite[\S17.3]{view} as part of an investigation into what happens when $R$ is not local.
\begin{proposition}\label{prop:in_gen_ideal}
	Let $x_1,...,x_n \in R$ be elements of $R$ and $I$ the ideal they generate. Assume $y_1,...,y_r \in I$ are elements of $I$, then there is an isomorphism
	\begin{equation}
		K(x_1,...,x_n,y_1,...,y_r) \cong K(x_1,...,x_n) \otimes \wedge R^r
	\end{equation}
\end{proposition}
\begin{proof}
	First, write $y_i = \sum_{j = 1}^n a_{ij}x_j$ for each $y_i$ and let $A$ denote the matrix $(a_{ij})$. Then there is an automorphism of $R^n \oplus R^r$ given by the matrix
	\begin{equation}
		F:= \begin{pmatrix}
			I & 0\\
			-A & I
		\end{pmatrix}
	\end{equation}
	indeed an inverse is given by
	\begin{equation}
		\begin{pmatrix}
			I & A\\
			0 & I
		\end{pmatrix}
	\end{equation}
	Notice that $F$ is such that $F(x_1,...,x_n,y_1,...,y_r) = (x_1,...,x_n,0,...,0)$.  We state without proof that the Koszul complex is functorial, and so we thus have
	\begin{equation}
		K(x_1,...,x_n,y_1,...,y_r) \cong K(x_1,...,x_n,0,...,0)
	\end{equation}
	Moreover, using Lemma \ref{lem:sum_tens} we have $K(x_1,...,x_n,0,...,0) \cong K(x_1,...,x_n) \otimes K(0,...,0) \cong K(x_1,...,x_n) \otimes \wedge R^r$. .
\end{proof}
\begin{cor}
	Let $M$ be any $R$-module, and $x_1,...,x_n,y_1,...,y_r$ as in Proposition \ref{prop:in_gen_ideal}. Then
	\begin{equation}
		H^\ast (M \otimes K(x_1,...,x_n,y_1,...,y_r))\cong H^\ast(M \otimes K(x_1,...,x_n)) \otimes \wedge R^r
	\end{equation}
	and so for each $i$,
	\begin{equation}
		H^i(M \otimes K(x_1,...,x_n,y_1,...,y_r)) \cong \sum_{i = j + k}H^k(M \otimes K(x_1,...,x_n)) \otimes \wedge^j R^r
	\end{equation}
	Thus
	\begin{equation}
		H^i(M \otimes K(x_1,...,x_n,y_1,...,y_r)) = 0
	\end{equation}
	if and only if
	\begin{equation}
		H^k(M \otimes K(x_1,...,x_n)) \cong 0\text{ for all }k\text{ such that }i-r \leq k \leq i
	\end{equation}
\end{cor}
\begin{proof}
	The first statement follows from flatness of $\wedge^j R^r$ (indeed, it is free), the rest are obvious.
\end{proof}



\subsection{Regular sequences are quasi-regular}
Now, let $(f_1,...,f_n)$ be regular in some ring $R$ and denote by $J$ the ideal generated by these elements. For any $m \geq 0$ the scalar multiplication by $R$ on $J^m/J^{m+1}$ descends to one of $R/J$, thus rendering $J^m/J^{m+1}$ an $R/J$-module. Moreover, these scalars can be extended to $(R/J)[x_1,...,x_n]$ by defining $x_i\cdot [r]_J = [f_i r]_J = [0]_J$. There is then an $(R/J)[x_1,...,x_n]$-module homomorphism
\begin{equation}
	\label{quasi}
	(R/J)[x_1,...,x_n] \to \bigoplus_{m \geq 0}J^m/J^{m+1}
\end{equation}
defined by the rule
\[x_1^{i_1}...x_n^{i_n} \mapsto f_1^{i_1}...f_n^{i_n}\operatorname{mod}J^{i_1 + ... + i_n + 1}\]
which is surjective.
\begin{defn}
	Such a sequence is \textbf{quasi-regular} if the above map is an isomorphism.
\end{defn}
Indeed this is to be thought of as a weakening of the notion of regular sequences, as justified by the following Lemma:
\begin{lemma}
	If a sequence $(f_1,...,f_n)$ of $R$ is regular, it is quasi-regular.
\end{lemma}
\begin{proof}
	Throughout, the notation $|I|$ where $I$ is a sequence of natural numbers will mean $\sum_{i \in I}i$.\\\\
	%
	We proceed by induction on $n$. When $n = 0$ notice that the composite
	\[(R/J) \stackrel{(\ref{quasi})}{\longrightarrow}\bigoplus_{m \geq 0}J^m/J^{m+1} \cong R/J\]
	is the identity map, so the result clearly holds for the base case.\\\\
	%
	Now say $n \geq 1$. Let $\sum_{|I| = m}[\alpha_I]_{J} [f^I]_{J^{m+1}} = [0]_{J^m}$, in other words, say $\sum_{|I| = m}\alpha_I f^I$ as an element of $R$ is in $J^{m+1}$. Let $\sum_{|I| = m}\alpha_I f^I = \sum_{|I'| = m + 1}\beta_{I'}f^{I'}$. By substituting each $\beta_{I'}$ by $\hat{\beta}_I := \beta_{I'}f_{i_1}$, we have $\sum_{|I| = m}\alpha_I f^I = \sum_{|I| = m}\hat{\beta}_If^I$, where each $\hat{\beta}_I \in J$. That is to say, $\sum_{|I| = m}\hat{\alpha}_If^I = 0$ where $\hat{\alpha}_I = \alpha_I - \hat{\beta}_I$. Thus we may assume that in fact $\sum_{|I| = m} \alpha_If^I = 0$. It remains to show that each $\alpha_I \in J$.\\\\
	%
	Next we rewrite $\sum_{|I| = m} \alpha_If^I$ as a sum where each occurrence of $f_n$ in $f^I$ has been factored out. We let $m'$ denote the largest integer such that a summand of $\sum_{|I| = m} \alpha_If^I$ contains $m'$ factors of $f_n$ in the product $f^I$:
	\[\sum_{|I| = m} \alpha_If^I = \sum_{j = 0}^{m'}\Big(\sum_{|I'| = m - j} \alpha_{I,j}f^{I',j}\Big)f_n^j = 0\]
	the relabelling of $\alpha_I$ by $\alpha_{I,j}$ is for clarity later on. We now prove that in such a setting, we have that $\alpha_I \in J$ by induction on $m'$.\\\\
	%
	Denote the ideal $(f_1,...,f_{n-1})$ by $J'$. If $m'$ = 0 then $\sum_{|I'| = m} \alpha_If^{I'} = 0$ where $f^{I'} \in (f_1,...,f_{n-1})^m$ and so each $\alpha_I \in J$ by the hypothesis of induction on $n$.\\\\
	%
	Now say $m' \geq 1$. Then (and this is the step which takes advantage of reducing the proof to the case when $\sum_{|I| = m} \alpha_If^I = 0$):
	\[\big(\sum_{|I'| = m - m'} \alpha_{I,m'}f^{I',j}\Big)f_n^{m'} = -\Big(\sum_{j = 0}^{m' - 1}\big(\sum_{|I'| = m - j} \alpha_{I,j}f^{I',j}\big)f_n^j\Big) \in (J')^{m-m'+1}\]
	That is to say, $\Big(\sum_{|I'| = m - m'}[\alpha_{I,m'}]_{J}[f^{I'}]_{(J')^{m-m'+1}}\Big)[f_n^{m'}]_{(J')^{m-m'+1}} = [0]_{(J')^{m - m' + 1}}$. It follows by the hypothesis of induction on $n$ that $f_n^{m'}\alpha_I \in J'$. Now we make use of the hypothesis that $(f_1,...,f_n)$ is regular, and indeed this is the key moment in the proof. Since $f_n^{m'}$ is not a zero divisor of $R/J'$, we deduce that $\alpha_{I,m'} \in J' \subseteq J$. It now remains to show that the remaining $\alpha_{I,j} \in J$.\\\\
	%
	For this, we write:
	\[\sum_{j = 0}^{m'}\Big(\sum_{|I'| = m-j}\alpha_{I,j}f^{I',j}\Big)f_n^j = \sum_{|I'| = m - j}\big(\alpha_{I,m'-1}f^{I',j} + f_n\alpha_{I,m'}f^{I',j}\big)f_n^{m'-1} + \sum_{j = 0}^{m' - 2}\Big(\sum_{|I'| = m-j}\alpha_{I,j}f^{I',j}\Big)f_n^{j} = 0\]
	so by the hypothesis of induction on $m'$ we have that $\alpha_{I,m'-1} + f_n\alpha_{I,m'} \in J$ and $\alpha_{I,j} \in J$ for all $j \leq m' - 2$. The final observation to make is that since $f_n\alpha_{I,m'} \in J$ it follows that $\alpha_{I,m'-1} \in J$.
\end{proof}
%
\subsection{Completion and quasi-regularity}

Let $R$ be a ring and $(f_1, \ldots, f_n)$ a sequence of elements in $R$. Let $I$ denote the ideal generated by $f_1, \ldots, f_n$ and $\hat{R}$ the $I$-adic completion of $R$. We recall that elements of $\hat{R}$ can be identified with elements in the following limit
\begin{equation}
	\hat{R} = \operatorname{Lim}\Big\{ R/I \leftarrow R/I^2 \leftarrow R/I^3 \leftarrow R/I^4 \leftarrow \ldots\Big\}
	\end{equation}
For an element $r \in R$ we write $[r]_i$ for the equivalence class represented by $r$ modulo $I^i$.

Any element $r \in \hat{R}$ can be written as a sequence $([r_1]_{1}, [r_2]_{2}, \ldots)$ for some elements $r_1, r_2, \ldots \in R$ and where for $j < i$ we have $r_j = r_i\operatorname{ mod }I^{j}$.

If $r = ([r_1]_1, [r_2]_2, \ldots)$ is such an element, then for all $i > 0$ we have $r_{i} - r_{i-1} \in I^{i-1}$ and so there exists $t_{i-1} \in I^{i-1}$ such that $r_{i} = r_{i-1} + t_{i-1}$. This allows us to rewrite $r$:
\begin{equation}
	r = (r_1, r_2, \ldots) = (r'_1, r'_1 + r'_2, r'_1 + r'_2 + r'_3, \ldots)
	\end{equation}
where $r_1 = r'_1$ and $r'_i = r_i - r_{i-1}$ for $i > 1$. Since each $r'_i \in I^{i-1}$ we can write $r'_i = r''_i t_i$ for some $t_{i-1} \in I^{i-1}, r_i'' \in R$. Taking $r_1'' := r_1'$, this second representation can be written more compactly as
\begin{equation}\label{eq:sum_rep}
	r'_1 + \sum_{i = 2}^\infty r_i'' t_{i-1}
	\end{equation}
With a change of index labelling, we have proven:
\begin{lemma}
	For any element $r \in \hat{R}$ there exists $\alpha_0, \alpha_1, \ldots \in R$ and $t_i \in I^{i}$ such that
	\begin{equation}
		r = \sum_{i = 0}^\infty \alpha_i t_i
		\end{equation}
	\end{lemma}
Now, given any $M = (m_1, \ldots, m_n) \in \bb{N}^n$ we denote by $f^M$ the element $f_1^{m_1}\ldots f_n^{m_n} \in R$. Since $I$ is generated by $f_1, \ldots, f_n$ we have that each $t_i = \sum_{M \in \bb{N}^n}\beta_{iM} f^M$ for some collection $\{ \beta_{iM} \}_{i \in I, M \in \bb{N}^n} \subseteq R$ where for each $M \in \bb{N}^n$ all but finitely many $\{ \beta_{iM} \}_{i \in I}$ are equal to $0$. So \eqref{eq:sum_rep} becomes
\begin{equation}
	\sum_{M \in \bb{N}^n}\Big(\sum_{i = 0}^\infty \alpha_i \beta_{iM}\Big) f^M
	\end{equation}
We can then set $\gamma_M := \sum_{i = 0}^\infty \alpha_i\beta_{iM}$ (note this sum is finite). For any $g \in I$ we have
\begin{equation}
	\sum_{M \in \bb{N}^n}(\gamma_M + g)f^M = \sum_{M \in \bb{N}^n}\gamma_M f^M
	\end{equation}
Thus, if $\sigma: R/I \lto R$ is a section (ie, a function $\sigma:R/I \lto R$ of \emph{sets} such that $\sigma \pi = \operatorname{id}_R$) to the projection $R \lto R/I$ then
\begin{equation}\label{eq:confusing_eq}
	\sum_{M \in \bb{N}^n}\gamma_M f^M = \sum_{M \in \bb{N}^n}\sigma(\gamma_M) f^M
	\end{equation}
where on the right hand side \eqref{eq:confusing_eq} we think of $\hat{R}$ as an $R/I$-algebra. The final remark to make is that if $(f_1, \ldots, f_n)$ is quasi-regular, then the coefficients $\sigma(\gamma_M)$ are uniquely determined by $r$. We have proven.
\begin{lemma}
	If $R$ is a ring,$(f_1, \ldots, f_n)$ a sequence of elements in $R$ and $I$ is the ideal generated by $f_1, \ldots, f_n$. Let $\sigma: R/I \lto R$ be a section to the projection $\pi: R \lto R/I$. Then for any $r \in \hat{R}$ (the $I$-adic completion of $R$) there exists a set $\{ \sigma_M \}_{M \in \bb{N}^n} \subseteq R$ such that
	\begin{equation}
		r = \sum_{M \in \bb{N}^n} \sigma(\gamma_M)f^M
		\end{equation}
	Moreover, the coefficients $\sigma(\gamma_M)$ are uniquely determined by $r$ if and only if $(f_1, \ldots, f_n)$ is a quasi-regular sequence.
	\end{lemma}




\section{Clifford algebras}
\subsection{Bilinear/Quadratic forms}
Throughout $V$ is a finite dimensional $k$-vector space. 

This Section considers vector spaces equipped with either a bilinear form or a quadratic form (which due to \ref{prop:bil_quad_form} amounts, in the case where $k$ is of characteristic not equal to 2,  to the same thing).
\begin{defn}
	A bilinear map $B:V \times V \lto k$ is sometimes called a \textbf{bilinear form}. If $v_1,...,v_n$ is a basis for $V$ then for any $u = u_1v_1 + \hdots u_n v_n,w = w_1v_1 + \hdots w_n v_n \in V$ the value $B(u,w)$ can be calculated by
	\begin{equation}
		\begin{bmatrix}
			w_1 & \hdots & w_n
		\end{bmatrix}
		\begin{bmatrix}
			B(v_1,v_1) & \hdots & B(v_1, v_n)\\
			\vdots & \ddots & \vdots\\
			B(v_n,v_1) & \hdots & B(v_n,v_n)
		\end{bmatrix}
		\begin{bmatrix}
			u_1\\
			\vdots\\
			u_n
		\end{bmatrix}
	\end{equation}
	and so given a choice of basis for $V$ there exists an isomorphism between the vector space of bilinear forms and the vector space of $n \times n$ matrices with entries in $k$. If $\scr{B}$ is a basis for $V$, the matrix corresponding to $B$ is denoted $[B]_{\scr{B}}$.
	
	A bilinear form $B: V \times V \lto k$ is \textbf{symmetric} if for all $v,u \in V$ we have $B(v,u) = B(u,v)$.
\end{defn}
\begin{defn}
	A \textbf{quadratic form} is a function $Q: V \lto k$ satisfying the following properties:
	\begin{itemize}
		\item for all $a \in k$ and $v \in V$, we have $Q(av) = a^2Q(v)$,
		\item the function $B: V \times V \lto k$ given by $B(v,u) = Q(v + u) - Q(v) - Q(u)$ is bilinear.
	\end{itemize}
\end{defn}
\begin{proposition}\label{prop:bil_quad_form}
	Let $B: V \times V \lto k$ be a symmetric bilinear form and $k$ a field of characteristic not equal to $2$. Then the function $Q_B: V \lto k$ given by $Q_B(v) = B(v,v)$ is a quadratic form.
	
	Also, given a quadratic form $Q: V \lto k$, the function $B_Q: V \times V \lto k$ given by $B_Q(v,u) = \frac{1}{2}\big(Q(v + u) - Q(v) - Q(u)\big)$ is a bilinear form.
\end{proposition}
\begin{proof}
	Easy.
\end{proof}
\begin{defn}\label{def:associated_forms}
	In the notation of Proposition \ref{prop:bil_quad_form}, $B_Q$ is the \textbf{bilinear form associated to $Q$} and $Q_B$ is the \textbf{quadratic form associated to $B$}. Notice that $B_Q$ is symmetric.
	
	We say that a bilinear form $B$ is \textbf{diagonalisable} if there exists a basis $\scr{B}$ for $V$ rendering $[B]_{\scr{B}}$ diagonal, similarly, we say that $Q$ is \textbf{diagonalisable}.
	
\end{defn}
\begin{proposition}\label{prop:diagonalisable_symmetric}
	A finite dimensional bilinear form $B: V \times V \lto k$ is diagonalisable if and only if it is symmetric.
\end{proposition}
\begin{proof}
	The bilinear form $B$ is symmetric if and only if there exists a basis with respect to which the matrix representation of $B$ is symmetric (which would imply the matrix representation with respect to \emph{any} basis is symmetric). So since $B$ is diagonalisable we have that $B$ is symmetric.
	
	Now we prove the converse. If $B$ maps everything to zero then the result is obvious so assume this is not the case. We first prove that there exists a vector $v$ such that $Q_B(v) = B(v,v) \neq 0$. Let $u_1,u_2 \in V$ be such that $B(u_1,u_2) \neq 0$. If $B(u_1,u_1) \neq 0$ or $B(u_2,u_2) \neq 0$ then we could take $v$ to be one of $u_1,u_2$, so assume $B(u_1,u_1) = B(u_2,u_2) = 0$. We have
	\begin{equation}
		Q(u_1 + u_2) = B(u_1 + u_2, u_1 + u_2) = B(u_1,u_2) + B(u_2,u_1) = 2B(u_1,u_2) \neq 0
	\end{equation}
	where we have used both the assumptions that $B$ is symmetric and that the characteristic of $k$ is not 2. We can thus take $v$ to be $u_1 + u_2$.
	
	We proceed by induction on the dimension of $V$, with the base case $\operatorname{dim}V = 1$ being trivial.
	
	Say $\operatorname{dim}V = n > 1$. Consider the map $\varphi_v: V \lto k$ given by $\varphi_v(u) = B(u,v)$. Since $B(v,v) \neq 0$ we have that $\operatorname{im}\varphi_v = k$ and so $\operatorname{ker}\varphi_v = \operatorname{dim}_kV - 1$. Since we are working with finite dimensional vector spaces that there exists implies a decomposition $V = \operatorname{ker}\varphi_v \oplus \operatorname{im}\varphi_v$. We have by the inductive hypothesis that $B\restriction_{\operatorname{ker}\varphi_v \times \operatorname{ker}\varphi_v}$ is diagonalisable. Fix a basis $\scr{B} := \lbrace v_1,...,v_{n-1}\rbrace$ of $\operatorname{ker}\varphi_v \times \operatorname{ker}\varphi_v$ so that the top left $n-1 \times n-1$ minor of the matrix representation of $B$ with respect to this basis is diagonal. We extend $\scr{B}$ to a basis $\scr{B}'$ for $V$ by taking $\scr{B} := \scr{B} \bigcup \lbrace v_n\rbrace$ with $v$ and notice that $B(v_i,v) = B(v,v_i) = 0$ for all $i = 1,...,n-1$ (using the decomposition $V = \operatorname{ker}\varphi_v \oplus \operatorname{im}\varphi_v$ from earlier). We thus have a basis $\lbrace v_1,...,v_{n-1},v\rbrace$ with respect to which the matrix representation of $V$ is diagonal.
\end{proof}

\begin{remark}
	In the proof of Propsition \ref{prop:diagonalisable_symmetric} we used the fact that a linear transformation $\varphi: V \lto W$ between two finite dimensional $k$-vector spaces induces a decomposition
	\begin{equation}
		V \cong \operatorname{ker}\varphi \oplus \operatorname{im}\varphi
		\end{equation}
	for some subspace $W$. To see this, we use the splitting lemma. There is always a short exact sequence
	\begin{equation}
		\begin{tikzcd}
			0\arrow[r] & \operatorname{ker}\varphi\arrow[r,rightarrowtail] & V\arrow[r,"{\varphi}"] & \operatorname{im}\varphi\arrow[r] & 0
			\end{tikzcd}
		\end{equation}
	Now pick a basis $\scr{B}$ for $\operatorname{im}\varphi$ and using choice, make a choice of lifts $\scr{C} := \{ v_b \mid \varphi(v_b) = b \}_{b \in \scr{B}}$. There is thus a linear transformation $\psi: \operatorname{im}\varphi \lto V$ which is given on basis vectors by $\psi(b) = v_b$. Clearly, $\varphi \psi = \operatorname{id}_{\operatorname{im}\varphi}$, and so the splitting lemma may be applied.
	\end{remark}

\begin{proposition}\label{prop:one_negative_one}
	Say $V$ is finite dimensional of dimension $n$. By Proposition \ref{prop:diagonalisable_symmetric} the quadratic form $Q$ is diagonalisable, in fact, more can be said:
	\begin{itemize}
		\item if $k = \bb{R}$ then there exists a basis for $V$ and $0 \leq r \leq n$ such that $Q$ with respect to this basis has diagonal entries
		\begin{equation}
			\lambda_1 = \hdots = \lambda_r = 1, \qquad \lambda_{r+1} = \hdots = \lambda_n = -1
		\end{equation}
		\item if $k = \bb{C}$ then there exists a basis for $V$ such that $Q$ with respect to this basis has diagonal entries
		\begin{equation}
			\lambda_1 = \hdots = \lambda_n = 1
		\end{equation}
	\end{itemize}
\end{proposition}
\begin{proof}
	Let $v_1,\hdots,v_n$ be a basis with respect to which $Q$ is diagonal with diagonal entries $\lambda_1,\hdots,\lambda_n$. We proceed by induction on $n$. Say $n = 1$ and let $e$ be the chosen basis vector of $V$,and say $k = \bb{R}$,  we have
	\begin{equation}
		B_Q(v_1,v_2) = v_2e\cdot \lambda_1 \cdot v_1 e =
		\begin{cases}
			v_2 \sqrt{\lambda_1}e\cdot 1 \cdot v_1\sqrt{\lambda_1} e,&\lambda_1 \geq 0,\\
			v_2 \sqrt{-\lambda_1}e\cdot -1 \cdot v_1\sqrt{-\lambda_1} e,& \lambda_1 < 0
		\end{cases}
	\end{equation}
	so we can replace the basis $e$ by either $\sqrt{\lambda_1}e$ or $\sqrt{-\lambda_1}e$ and we are done. In the case when $k = \bb{C}$, there always exists a square root of $\lambda_1$.
	
	The logic of the inductive step is exactly similar.
\end{proof}
\begin{proposition}\label{prop:signature}
	Say $V$ is a real vector space of dimension $n$. By Proposition \ref{prop:one_negative_one} there exists a basis of $V$ for which $[B]_{\scr{B}}$ is diagonal with all entries equal to either 1 or $-1$. The triple $(n_{+},n_{-},n_0)$ consisting of the number $n_{+}$ of positive entries, the number $n_{-}$ of negative entries, and the number $n_{0}$ of entries equal to zero in a $[B]_{\scr{B}}$ is independent of the choice of diagonalising basis $\scr{B}$. 
\end{proposition}
\begin{proof}
	Write
	\begin{equation}
		[B]_{\scr{B}} = 
		\begin{bmatrix}
			I_{p} & &\\
			& -I_{q} &\\
			& & 0_{r}
		\end{bmatrix}
	\end{equation}
	Denote by $W \subseteq V$ the largest subspace such that $B\restriction_{W \times W}$ is positive definite, ie, $B(w,w) > 0$ for all $w\in W$.  Letting $w = w_1v_1 + \hdots w_nv_n$ and calculating $B(w,w)$ using $[B]_{\scr{B}}$ we have
	\begin{equation}
		w^T[B]_{\scr{B}}w = w_1^2 + \hdots w_p^2 - w_{p+1}^2 - \hdots - w_{p+q}^2
	\end{equation}
	and so $w^t[B]_{\scr{B}}w >0$ if and only if $w_{p+1} = \hdots = w_{p+q} = 0$. We thus have $$W \subseteq \operatorname{Span}(v_1,...,v_p)$$ Letting $W'$ denote this span, we clearly also have $W' \subseteq W$, implying $p = \operatorname{dim}W$. Thus $p$ has been related to a value which is basis independent and so $p$ is an invariant. The remaining invariances follow from the rank-nullity Theorem.
\end{proof}

\begin{defn}
	In the notation of Proposition \ref{prop:signature}, the triple $(n_{+},n_{-},n_0)$ is the \textbf{signature} of $B$.
	
	If $n_0 = 0$ then the bilinear form is \textbf{nondegenerate}.
\end{defn}

\begin{remark}\label{rmk:signature_complex}
	The number of entries equal to $1$ in a matrix representation of a symmetric bilinear form on a finite dimensional complex vector space is also an invariant, this follows directly from the rank-nullity Theorem.
\end{remark}

\subsection{Clifford algebras}
Throughout, we denote by $(V,Q)$ a quadratic form, consisting of a finite dimensional $k$-vector space $V$ and a quadratic form $Q: V \lto k$ on $V$. The field $k$ is assumed to have characteristic not equal to 2.
\begin{defn}\label{def:clifford_univ_prop}
	A pair $(C_Q,j)$ consisting of a $k$-algebra $C_Q$ and a linear transformation $j: V \lto C_Q$ such that
	\begin{equation}
		\forall v \in V, j(v)^2 = Q(v)\cdot 1
	\end{equation}
	is a \textbf{clifford algebra for $(V,Q)$} if it is universal amongst such maps. That is, for every pair $(D,k)$ consisting of a $k$-algebra $D$ and a linear transformation $k: V \lto D$ satisfying
	\begin{equation}
		\forall v \in V, k(v)^2 = Q(v)\cdot 1
	\end{equation}
	there exists a unique $k$-algebra homomorphism $m: C_Q \lto D$ such that the following diagram commutes
	\begin{equation}
		\begin{tikzcd}
			V\arrow[r,"j"]\arrow[rd,"k"] & C_Q\arrow[d,"m"]\\
			& D
		\end{tikzcd}
	\end{equation}
\end{defn}
\begin{proposition}\label{prop:clifford_construction}
	A Clifford algebra for $(V,Q)$ always exists and is essentially unique (unique up to unique isomorphism) amongst those algebras satisfying the unversal property given in Definition \ref{def:clifford_univ_prop}.
\end{proposition}
\begin{proof}[Proof (sketch)]
	We construct the tensor algebra
	\begin{equation}
		T(V) := \bigoplus_{i \geq 0}V^{\otimes i}
	\end{equation}
	(where $V^{\otimes 0} := k$) quotiented by the ideal $I$ generated by the set $\lbrace v \otimes v - Q(v)\cdot 1\rbrace_{v \in V}$. The map $j: V \lto C_Q$ is the inclusion $V \lto T(V)$ composed with the projection $T(V) \lto T(V)/I$.
\end{proof}
Notice that $j$ given in the proof of Proposition \ref{prop:clifford_construction} is injective.
\begin{example}\label{ex:clifford_exterior}
	Say $Q: V \lto k$ maps everything to zero. Then the associated Clifford Algebra $(C_Q,l)$ is such that $C_Q \cong \bigwedge V$.
	
	To see this, define $\varphi: V \lto \bigwedge V$ by $v \mapsto v$. This is such that $\varphi(v)^2 = 0$ and so by the universal property of $(C_V,l)$ there exists a $k$-algebra homomorphism $\overline{\varphi}: C_Q \lto \bigwedge V$. This is clear as the definitions of $C_Q$ and $\bigwedge V$ are the same.
\end{example}
Example \ref{ex:clifford_exterior} shows that when $Q$ is the 0 quadratic form then the associated Clifford algebra is isomorphic to the exterior algebra, in fact, if $Q$ is \emph{not} the zero quadratic form then the associated Clifford algebra is \emph{not} isomorphic to the exterior algebra as an \emph{algebra} but whatever $Q$ is, $C_Q$ is always \emph{linearly} isomorphic (isomorphic as a vector space) to the exterior algebra, as the next Proposition states:
\begin{proposition}\label{prop:linear_iso}
	The underlying vector spaces of $C_Q$ and $\bigwedge V$ are isomorphic.
\end{proposition}
Proposition \ref{prop:linear_iso} will follow from a series of observations which cover a broader scope of theory, which we now present.

Consider the linear map $k: V \lto C_Q$ given by $k(v) = -j(v)$ which clearly satisfies $k(v)^2 = Q(v)\cdot 1$. There is thus an induced morphism $\beta: C_Q \lto C_Q$ rendering the following diagram commutative:
\begin{equation}
	\begin{tikzcd}
		V\arrow[r,"j"]\arrow[dr,"k"] & C_Q\arrow[d,"\beta"]\\
		& C_Q
	\end{tikzcd}
\end{equation}
We have that $\beta^2 = \operatorname{id}_{C_Q}$. 

\begin{defn}
	The involution $\beta$ is the \textbf{involution associated with the Clifford Algebra $(C_Q,j)$}.
\end{defn}
Recall that for an arbitrary involution $f: V \lto V$ (where $V$ is a vector space over a field of characteristic not equal to 2) we have
\begin{equation}
	\forall v \in V, v = 1/2(f(v) + v) + v - 1/2(f(v) + v) = 1/2(f(v) + v) + 1/2(v - f(v))
\end{equation}
where we notice
\begin{equation}
	f(1/2(f(v) + v)) = 1/2(f(v) + v),\quad \text{and}\quad f(1/2(v - f(v))) = 1/2(f(v) - v)
\end{equation}
and so
\begin{equation}
	V = E_1 + E_{-1}
\end{equation}
where $E_i$ is the $i^\text{th}$ Eigenspace of $f$. 

Applying this observation to the situation of Clifford algebras, we have:
\begin{equation}
	C_Q^0 := \lbrace v \in C_Q^0 \mid \beta(v) = v\rbrace, \qquad C_Q^1 := \lbrace v \in C_Q^1 \mid \beta(v) = -v\rbrace
\end{equation}
and
\begin{equation}
	C_Q = C_Q^0 \oplus C_Q^1
\end{equation}
Thus the Clifford algebra $(C_Q,j)$ associated to a quadratic form $Q: V \lto k$ is naturally a $\bb{Z}_2$-graded algebra.
\begin{proposition}\label{prop:sum_tensor}
	For quadratic forms $Q_1: V_1 \lto k, Q_2: V_2 \lto k$ we have
	\begin{equation}
		C_{Q_1 \oplus Q_2} \cong C_{Q_1} \otimes C_{Q_2}
	\end{equation}
\end{proposition}
\begin{proof}
	Consider the linear transformation
	\begin{align*}
		T: V_1 \oplus V_2 &\lto C_{Q_1} \otimes C_{Q_2}\\
		(v_1,v_2) &\longmapsto v_1 \otimes 1 + 1 \otimes v_2
	\end{align*}
	We have:
	\begin{align*}
		T(v_1,v_2)^2 &= (v_1 \otimes 1 + 1 \otimes v_2)^2\\
		&= (v_1 \otimes 1 + 1 \otimes v_2)(v_1 \otimes 1 + 1 \otimes v_2)\\
		&= v_1^2 \otimes 1 + v_1 \otimes v_2 - v_1 \otimes v_2 + 1 \otimes v_2^2\\
		&= Q_{V_1}(v_1) \otimes 1 + 1 \otimes Q_{V_2}(v_2)\\
		&= (Q_{V_1}(v_1) + Q_{V_2}(v_2))(1 \otimes 1)\\
		&= Q_{V_1 \oplus V_2}(v_1,v_2)(1 \otimes 1)
	\end{align*}
	So by the universal property of the Clifford algebra $(C_Q,j)$ there exists a $k$-algebra homomorphism $\hat{T}: C_{Q_1 \oplus Q_2} \lto C_{Q_1} \otimes C_{Q_2}$. First we prove surjectivity, it is sufficient to prove that every pure tensor $x \otimes y \in C_{Q_1} \otimes C_{Q_2}$ is mapped onto by some element by $\hat{T}$. Write $x \otimes y = v_1\hdots v_n \otimes u_1 \hdots u_m$ for some $u_1,...,u_n \in C_{Q_1}, v_1,...,v_m \in C_{Q_2}$. Since
	\begin{equation}
		v_1\hdots v_n \otimes u_1 \hdots u_m = (v_1 \otimes 1)\hdots(v_n \otimes 1)(1 \otimes u_1)\hdots (1 \otimes u_m)
	\end{equation}
	it suffices to show that for all pairs $(v,u) \in V_1 \times V_2$ that $v \otimes u \in C_{Q_1} \otimes C_{Q_2}$ is mapped onto by some element by $\hat{T}$. Indeed:
	\begin{align*}
		T\big((v,0)(0,u)\big) &= (v \otimes 1 + 1 \otimes 0)(0 \otimes 1 + 1 \otimes u)\\
		&= v\otimes u
	\end{align*}
	Surjectivity follows.
	
	\textcolor{red}{Injectivity?}
\end{proof}
\begin{defn}
	A bilinear form or a quadratic form is \textbf{finite dimensional} if $V$ is.
\end{defn}
For the next result, recall that a finite dimensional bilinear form is diagonalisable if and only if it is symmetric (Proposition \ref{prop:diagonalisable_symmetric}):

We are now in a position to describe a basis for $C_Q$ given one for $V$:
\begin{proposition}\label{prop:decomp_even_odd}
	Let $v_1,...,v_n$ be a basis for $V$. The set:
	\begin{equation}
		\scr{B} := \lbrace v_{i_1}...v_{i_m} \mid m \leq n, v_{j} \in V, 0 \leq i_1 < \hdots < i_m \leq n\rbrace
	\end{equation}
	forms a basis for $C_Q$. In particular,
	\begin{equation}\label{eq:dimension_clifford}
		\operatorname{dim}_kC_Q = 2^{\operatorname{dim}_kV}
	\end{equation}
\end{proposition}
\begin{proof}
	This set clearly linearly generates $C_Q$ and so it suffices to show that \eqref{eq:dimension_clifford} holds.
	
	By Proposition \ref{prop:diagonalisable_symmetric} we have that $Q = Q_1 \oplus \hdots \oplus Q_n$ and by Proposition \ref{prop:sum_tensor} it follows that $C_{Q_1 \oplus \hdots \oplus Q_n} \cong C_{Q_1} \otimes \hdots \otimes C_{Q_n}$. Thus it suffices to prove the case when $\operatorname{dim}_kV = 1$. This can be directly analysed; we know
	\begin{equation}
		C_Q \cong C^0_Q \oplus C^1_Q
	\end{equation}
	and $C^0_Q = k, C^1_Q = k\cdot e$, where $e \neq 0$. Thus the dimension of $C_Q$ in this case is 2.
\end{proof}
\begin{proposition}
	Say $V$ is finite dimensional and $v_1,...,v_n$ is a basis such that $B(v_i,v_j) = 0$ for all $i \neq j$. Then the Clifford algebra $C_Q$ is multiplicatively generated by $v_1,...,v_n$ which satisfy the relations
	\begin{equation}\label{eq:clifford_relations}
		v_i^2 = Q(v_i),\qquad v_iv_j + v_jv_i = 0, i \neq j
	\end{equation}
\end{proposition}
\begin{proof}
	The only non-obvious part follows from the calculation
	\begin{align*}
		(v_i + v_j)^2 &= Q(v_i + v_j)\\
		&= B(v_i + v_j, v_i + v_j)\\
		&= B(v_i,v_i) + 2B(v_i,v_j) + B(v_j,v_j)\\
		&= Q(v_i) + Q(v_j)\\
		&= v_i^2 + v_j^2
	\end{align*}
	which implies
	\begin{equation}
		v_iv_j + v_jv_i = 0, i \neq j
	\end{equation}
\end{proof}
Thus we may think of a Clifford algebra with respect to a finite quadratic form as the free algebra on $\operatorname{dim}_kV$ elements subject to the relations \eqref{eq:clifford_relations}.

\subsection{Clifford algebras of real or complex bilinear forms}
In this Section we sometimes will think of the Clifford algebra as associated to a symmetric bilinear form, rather than a quadratic form. There is no difficult difference, but we note that the correct universal property of $(C_B,j)$ is:
\begin{equation}
	\forall v_1,v_2 \in V, j(v_1)j(v_2) + j(v_2)j(v_1) = 2B(v_1,v_2)\cdot 1
\end{equation}
We also introduce new notation; the Clifford algebra associated to a bilinear form $B: V \times V \lto k$ is denoted $C(V,B)$.

We can restate Remark \ref{rmk:signature_complex} in terms of Clifford algebras:
\begin{cor}\label{cor:signature_determines}
	Let $k\in \lbrace \bb{R},\bb{C}\rbrace$. All Clifford algebras of quadratic forms over finite dimensional, $k$-vector spaces which admit the same signature are isomorphic.
\end{cor}
\begin{notation}
	We denote:
	\begin{itemize}
		\item the Clifford algebra associated to the quadratic form $(\bb{R}^n, -x_1^2 - \hdots - x_n^2)$ by $C_n$,
		\item the Clifford algebra associated to the quadratic form $(\bb{R}^n, x_1^2 + \hdots + x_n^2)$ by $C_n'$,
		\item the Clifford algebra associated to the quadratic form $(\bb{C}^n, z_1^2 + \hdots + z_n^2)$ by $C_n^{\bb{C}}$.
	\end{itemize}
where these quadratic forms are written with respect to the respective standard bases.
\end{notation}

Throughout this Section, $V$ is assumed to be a vector space over $k$ with $k \in \lbrace \bb{R},\bb{C}\rbrace$, and $B: V \times V \lto k$ is a bilinear form.
Given a real algebra $A$, the \emph{complexification} is the $\bb{C}$-algebra $A \otimes_\bb{R} \bb{C}$ with multiplication given by 
\begin{equation}
	\big((x \otimes z),(y\otimes w)\big)\longmapsto (xy \otimes zw)
\end{equation}
Also, given a bilinear form $B: V \times V \lto k$ where $V$ is a real vector space, we define the \emph{complexification} of $B$ as $B_{\bb{C}}: V \otimes_{\bb{R}} \bb{C} \lto \bb{C}$ given by
\begin{equation}
	B_{\bb{C}}\big((v_1 \otimes z_1),(v_2 \otimes z_2)\big) = B(v_1,v_2)z_1z_2
\end{equation}
The following Proposition shows that the Clifford algebra of a complexification behaves well:
\begin{proposition}
	We have
	\begin{equation}
		C(V \otimes_{\bb{R}} \bb{C}, B_{\bb{C}}) \cong C(V,B) \otimes_{\bb{R}} \bb{C}
	\end{equation}
\end{proposition}
\begin{proof}
	Consider the map $\varphi: V \otimes_{\bb{R}}\bb{C} \lto C(V,B) \otimes_{\bb{R}} \bb{C}$ given by $\varphi(v \otimes z) = v \otimes z$. This is such that
	\begin{equation}
		\varphi(v \otimes z)^2 = (v \otimes z)^2 = v^2 \otimes z^2 = B(v,v)z^2 \cdot 1 \otimes 1 = B_{\bb{C}}\big((v\otimes z),(v\otimes z)\big)\cdot 1
	\end{equation}
	So $\varphi$ induces a map $\hat{\varphi}: C(V \otimes_{\bb{R}}\bb{C}) \lto C(V,B) \otimes_{\bb{R}} \bb{C}$ which is an isomorphism with inverse induced by the bilinear map $C(V,B) \times \bb{C} \lto C(V \otimes_{\bb{R} }\bb{C}, B_{\bb{C}})$ given by $(x,z) \longmapsto x \otimes z$.
\end{proof}
\begin{lemma}\label{lem:complexification}
	We have
	\begin{equation}
		C_n^{\bb{C}} \cong C_n \otimes_{\bb{R}} \bb{C} \cong C_n' \otimes_{\bb{R}} \bb{C}
	\end{equation}
\end{lemma}
\begin{proof}
	For $i = 1, \ldots, n$ let $\varphi_i: \bb{C} \lto \bb{R}^n \otimes_\bb{R} \bb{C}$ denote the map defined by linearity and the rule $z \longmapsto e_i \otimes z$. These induce a map $\varphi: \bb{C}^n \lto \bb{R}^n \otimes \bb{C}$ which is the unique such that for all $i = 1, \ldots, n$ we have $\varphi \iota_i = \varphi_i$ where $\iota_i: \bb{C} \lto \bb{C}^n$ is the $i^{\text{th}}$ canonical inclusion.
	
	The map $\varphi$ has an inverse $\psi$ which is given by linearity and the rule $e_i \otimes z \longmapsto (0, \ldots, z, \ldots, 0)$ where every entry is $0$ other than the $i^{\text{th}}$ slot which is occupied by $z$.
	
	To see that this is indeed an inverse, notice
	\begin{equation}
		\varphi \psi (e_i \otimes z) = \varphi (0, \ldots, z, \ldots, 0) = e_i \otimes z
		\end{equation}
	and
	\begin{equation}
		\psi \varphi (z_1, \ldots, z_n) = \psi (\sum_{i = 1}^n e_i \otimes z_i) = \sum_{i = 1}^n (0, \ldots, z_i, \ldots, 0) = (z_1, \ldots, z_n)
		\end{equation}
	Next, given $(z_1, \ldots, z_n), (w_1, \ldots, w_n) \in \bb{C}^n$ we have
	\begin{align*}
		B_{C_n' \otimes \bb{C}}\big(\varphi(z_1, \ldots, z_n), \varphi(w_1, \ldots, w_n)\big) &= B_{C_n' \otimes \bb{C}}(\sum_{i = 1}^n e_i \otimes z_i, \sum_{j = 1}^n e_j \otimes w_j)\\
		&= \sum_{i,j = 1}^n B_{C_n'}(e_i, e_j)z_iw_j\\
		&= \sum_{i = 1}^n z_iw_i
		\end{align*}
	This implies that $\varphi$ induces an isomorphism $C_n^{\bb{C}} \cong C_n'$.
	
	To obtain an isomorphism $C_n^{\bb{C}^n} \cong C_n \otimes \bb{R}$ we compose $\varphi$ with the map $\bb{R}^n \otimes \bb{C} \lto \bb{R}^n \otimes \bb{C}$ defined by linear and the rule $e_i \otimes z \longmapsto e_i \otimes i z$ and proceed similarly to before.
\end{proof}
\begin{example}\label{ex:em_two}
	We have $C_2^{\bb{C}} \cong C_2 \otimes_{\bb{R}}\bb{C}$, and the latter algebra is generated by $e_1,e_2$ satisfying
	\begin{equation}\label{eq:clifford_c_2}
		e_1^2 = e_2^2 = -1,\qquad e_1e_2 + e_2e_1 = 0
	\end{equation}
	On the other hand, the underlying vector space of the complex algebra $M_2(\bb{C})$ has a basis
	\begin{equation}
		I = \begin{bmatrix}
			1 & 0\\
			0 & 1
		\end{bmatrix}
		, g_1 = 
		\begin{bmatrix}
			i & 0\\
			0 & -i
		\end{bmatrix}, g_2 =
		\begin{bmatrix}
			0 & i \\
			i & 0
		\end{bmatrix}, T = 
		\begin{bmatrix}
			0 & -i\\
			i & 0
		\end{bmatrix}
	\end{equation}
	satisfying:
	\begin{equation}\label{eq:generators_matrices}
		g_1^2 = g_2^2 = -I,\qquad g_1g_2 + g_2g_1 = 0,
	\end{equation}
	which implies $C_2^{\bb{C}} \cong M_2(\bb{C})$.
\end{example}
A final isomorphism (Proposition \ref{prop:complex_plus_two}) allows for a structure Theorem (Theorem \ref{thm:structure_clifford})
\begin{proposition}\label{prop:complex_plus_two}
	We have
	\begin{equation}
		C_{n+2} \cong C_n' \otimes_{\bb{R}}C_2,\qquad C_{n+2}' \cong C_n \otimes_{\bb{R}}C_2'
	\end{equation}
	Here the tensor product is the usual one for algebras.
\end{proposition}
\begin{proof}
	We satisfy ourselves with a proof sketch. The key Definition is the following:
	\begin{equation}
		u: \bb{R}^2 \lto C_n' \otimes_{\bb{R}}C_2
	\end{equation}
	defined on basis vectors $e_1,e_2 \in \bb{R}^{n+2}$ as:
	\begin{equation}
		u(e_1) = 1 \otimes e_1,\quad u(e_2) = 1 \otimes e_2,\quad u(e_j) = e_{j-2} \otimes e_1e_2, j = 3,...,n+2
	\end{equation}
	and the key calculation is
	\begin{align*}
		u(e_j)^2 &= (e_{j - 2} \otimes e_1e_2)^2\\
		&= e_{j-2}^2 \otimes e_1e_2e_1e_2\\
		&= 1 \otimes -e_1^2e_2^2\\
		&= -1 \otimes 1
	\end{align*}
In the penultimate step we have used the fact that $e_{j-2}^2 = 1$ in $C_n'$ and that $e_1e_2 + e_2e_1 = 0$ in $C_2$.
\end{proof}
\begin{remark}
	Notice that had we mapped $u$ into $C_n \otimes_{\bb{R}} C_2$ instead of into $C_n' \otimes_{\bb{R}}C_2$ then $u(e_{j})^2 = 1$ which would not induce a map $C_{n+2} \lto C_n \otimes_{\bb{R}}C_2$.
	\end{remark}
\begin{remark}
	In Proposition \ref{prop:complex_plus_two}, one might suggest (incorrectly) defining $u: C_{n+2} \lto C_n \otimes_{\bb{R}}C_2$ by
	\begin{equation}
		u(e_1) = 1 \otimes e_1,\quad u(e_2) = 1 \otimes e_2,\quad u(e_j) = e_{j-2} \otimes 1, j = 3,...,n+2
	\end{equation}
	but this does not work as then (for example)
	\begin{align*}
		u(e_1)u(e_3) + u(e_3)u(e_1) &= (1 \otimes e_1)(e_1 \otimes 1) + (e_1 \otimes 1)(1 \otimes e_1)\\
		&= 2e_1 \otimes e_1 \neq 0
	\end{align*}
\end{remark}
\begin{cor}
	We have
	\begin{equation}
		C_{n+2}^{\bb{C}} \cong C_n^{\bb{C}} \otimes_{\bb{C}}M_2(\bb{C})
	\end{equation}
	given explicitly by the following ($g_1,g_2$ are as in Example \ref{ex:em_two})
	\begin{equation}
		e_1 \longmapsto 1 \otimes e_1,\quad e_2 \longmapsto 1 \otimes e_2,\quad e_j \longmapsto ie_{j-2} \otimes g_1g_2, j = 3,...,n+2
	\end{equation}
\end{cor}
\begin{proof}
	This follows from an algebraic manipulation:
	\begin{align*}
		C_{n+2}^{\bb{C}} &\cong C_{n+2} \otimes_{\bb{R}}\bb{C}\\
		&\cong (C'_n \otimes_{\bb{R}} C_2) \otimes_{\bb{R}}\bb{C}\\
		&\cong (C'_{n}\otimes_{\bb{R}}\bb{C}) \otimes_{\bb{C}} (C_2 \otimes_{\bb{R}} \bb{C})\\
		&\cong C_{n}^{\bb{C}} \otimes_{\bb{C}}C_2^{\bb{C}}\\
		&\cong C_{n}^{\bb{C}} \otimes_{\bb{C}}M_2(\bb{C})
	\end{align*}
	We note that for $j > 2$, the element $e_j$ is mapped along these isomorphisms in the following way:
	\begin{align}
		e_j &\longmapsto e_j \otimes_{\bb{R}} 1\\
		&\longmapsto (e_{j-2} \otimes_{\bb{R}} e_1e_2) \otimes_{\bb{R}} 1\\
		&\longmapsto (e_{j-2} \otimes_{\bb{R}} 1) \otimes_{\bb{C}} (e_1e_2 \otimes_{\bb{R}} 1)\\
		&\label{eq:factor_of_i}\longmapsto e_{j-2} \otimes_{\bb{C}} ie_1e_2\\
		&\longmapsto ie_{j-2} \otimes_{\bb{C}} g_1g_2
	\end{align}
\end{proof}
\begin{thm}\label{thm:structure_clifford}
	\begin{itemize} There is the following decomposition:
		\item If $n = 2k$ is even,
		\begin{equation}
			C_n^{\bb{C}} \cong M_2(\bb{C}) \otimes \hdots \otimes M_2(\bb{C}) \cong \operatorname{End}(\bb{C}^2 \otimes \hdots \otimes \bb{C}^2) \cong \operatorname{End}((\bb{C}^{2})^{\otimes k})
		\end{equation}
		given explicitly by the following, we make use of the function
		\begin{align*}
			\alpha(j) = \begin{cases}
				1,& j\text{ odd},\\
				2, & j\text{even}
			\end{cases}
		\end{align*}
		\begin{equation}
			e_j \longmapsto I \otimes \hdots \otimes I \otimes g_{\alpha(j)} \otimes T \otimes \hdots \otimes T
		\end{equation}
		\item if $n = 2k+1$ is odd,
		\begin{equation}
			C_n^{\bb{C}} \cong \operatorname{End}(\bb{C}^{2^k}) \oplus \operatorname{End}(\bb{C}^{2^k})
		\end{equation}
	\end{itemize}
\end{thm}
Consider a finitely generated, free complex vector space $F_n = \bb{C}\theta_1 \oplus \ldots \oplus \bb{C}\theta_n$ along with its dual $F^\ast$. We look at the special case of the above theory when $V = F \oplus F^\ast$. We begin by defining the following bilinear form on $V$.
\begin{align*}
	B: V \times V &\lto \bb{C}\\
	\big((x, \nu), (y, \mu)\big) &\longmapsto \frac{1}{2}\big(\nu(y) + \mu(x)\big)
\end{align*}
The Clifford algebra $C_n(V, B)$ with respect to this bilinear form is the associative $\bb{Z}_2$-graded commutative $\bb{C}$-algebra generated by elements $\gamma_1, \ldots, \gamma_n, \gamma^\dagger, \ldots, \gamma_n^\dagger$ subject to the following conditions, where $[a,b] = ab - (-1)^{|a| |b|}ba$ and $|\gamma_i| = |\gamma_i^\dagger| = 1,\forall i$.
\begin{equation}
	[\gamma_i, \gamma_j] = 0\quad [\gamma_i^\dagger, \gamma_j^\dagger] = 0\quad [\gamma_i, \gamma_j^\dagger] = \delta_{ij}
\end{equation}
Let $S_n$ denote the exterior algebra of $F_n$.
\begin{equation}
	S_n := \bigwedge F_n = \bigwedge (\bb{C}\theta_1 \oplus \ldots \oplus \bb{C}\theta_n)
\end{equation}

\begin{lemma}
	There is an isomorphism of $\bb{C}$-algebras
	\begin{align*}
		\psi: C_n(V,B) &\lto \operatorname{End}_{\bb{C}}(S_n)\\
		\gamma^\dagger &\longmapsto \theta_i \wedge (\und{0.2})\\
		\gamma &\longmapsto \theta_i  \lrcorner( \und{0.2})
	\end{align*}
\end{lemma}
\begin{proof}
	It is clear that $\operatorname{End}_{\bb{C}}(S_n)$ is a free vector space and that the set $\{ \theta_i \wedge (\und{0.1}), \theta_i \lrcorner(\und{0.1}) \}$ is linearly independent.
	
	Consider the Clifford algebra $C_{2n}^{\bb{C}}$. Consider the map $\varphi: C_{2n}^{\bb{C}} \lto C_n(V,B)$ defined by linearity and the rule
	\begin{equation}
		e_i \longmapsto
		\begin{cases}
			i(\gamma_i^\dagger \gamma_i - \gamma_i \gamma_i^\dagger),&i = 1, \ldots, n\\
			i(\gamma_i + \gamma_i^\dagger), &i = n+1, \ldots, 2n
			\end{cases}
		\end{equation}
	We notice that $(\gamma_i^\dagger \gamma_i - \gamma_i \gamma_i^\dagger)(\gamma_i + \gamma_i^\dagger) = \gamma_i^\dagger - \gamma_i$ and so the set $\{ i(\gamma_i^\dagger \gamma_i - \gamma_i \gamma_i^\dagger), i(\gamma_i + \gamma^\dagger_i) \}_{i = 1, \ldots, n}$ is a generating set for $C_n(V,B)$. Moreover, this set is linearly independent and so indeed is a basis. This implies that $\varphi$ is an isomorphism of the underlying vector spaces, and one checks that it respects the Bilinear form and so is an isomorphism of Clifford algebras.
	
	Under the isomorphism $C_{2n}^{\bb{C}} \cong \operatorname{End}((\bb{C}^2)^{\otimes n})$ we have $i(\gamma_i^\dagger \gamma_i - \gamma_i \gamma_i^\dagger) \longmapsto I \otimes \ldots \otimes I \otimes g_{2} \otimes T \otimes \ldots \otimes T$ and $i(\gamma_i + \gamma_i^\dagger) \longmapsto I \otimes \ldots \otimes I \otimes g_{1} \otimes T \otimes \ldots \otimes T$. Thus the result follows from Theorem \ref{thm:structure_clifford}.
	\end{proof}









\begin{defn}
	Let $Q_i: V_i \lto k$ be quadratic forms for $i = 1,2$. Let $f: V_1 \lto V_2$ be a linear map, by composing with the inclusion $l: V_2 \lto C_{Q_2}$ there is an induced map $\varphi: V_1 \lto C_{Q_2}$ such that for all $v \in V_1$ we have
	\begin{equation}
		\varphi(v)^2 = f(v)^2 = Q_2(f(v))\cdot 1
	\end{equation}
	and so if $Q_2(f(v)) = Q_1(v)$ for all $v \in V$ we have by the universal property of $C_{Q_1}$ that there exists a unique morphism $C_{Q_1} \lto C_{Q_2}$ which we denote by $C(f)$.
\end{defn}
\begin{lemma}
	The map $C(f)$ is an isomorphism if $f$ is.
\end{lemma}
\begin{proof}
	Easy.
\end{proof}



\section{The residue}
\subsection{Hochschild Cohomology}
Let $R$ be a commutative ring and $A$ a (not necessarily commutative) associative $R$-algebra, via some structure map $h: A \lto R$ say.
\begin{defn}
	An \textbf{$R$-$R$-bimodule} $M$ is a left $R$-module which is also a right $R$-module, and which satisfies the following compatibility axiom:
	\begin{equation}
		\forall r, r' \in R, \forall m \in M, (rm)r' = r(mr')
		\end{equation}
	\end{defn}
\begin{defn}
	We denote by $R^{\operatorname{op}}$ the \textbf{opposite algebra of $R$} which has the same underlying set as $R$ and with multiplication given by
	\begin{equation}\label{eq:op_mult}
		r_1 \cdot_{R^{\operatorname{op}}}r_2 = r_1 \cdot r_2
	\end{equation}
	where the multiplication on the left hand side of \eqref{eq:op_mult} is understood as in the opposite algebra, and multiplication on the right hand side of \eqref{eq:op_mult} is understood as in the algebra $R$.
	
	Since $A$ is commutative, the $A$-algebra $R$ is also a right $A$-algebra, with multiplication given by $r a := a r$ for $r \in R, a \in A$. Thus, we can form the tensor product $R \otimes_A R^{\operatorname{op}}$ where $R$ on the left is thought of as a right $A$-module, and $R^{\operatorname{op}}$ on the right is thought of as a left $A$-module. This module $R \otimes_A R^{\operatorname{op}}$ is the \textbf{enveloping algebra} and is denoted $R^e$.
	\end{defn}
There is a correspondence between left $R^e$-modules and $R$-$R$-bimodules.
\begin{defn}
	Let $B_n$ denote the left $R^e$-module
	\begin{equation}\label{eq:bar_tensor}
		B_n := R^e \otimes \bigotimes_{i = 1}^nR/A
		\end{equation}
	where $A$ is seen as a subalgebra of $R$ via $h$. All tensor products in \eqref{eq:bar_tensor} are over $A$. A pure tensor $(r \otimes r') \otimes r_1 \otimes \cdots \otimes r_n$ in $T_A^n(A,R)$ will be denoted
	\begin{equation}
		r [r_1 \mid \cdots \mid r_n] r'
		\end{equation}
	We define the following family of $R^e$-linear maps for $n \geq 1$
	\begin{align*}
		\partial_{n}: B_n &\lto B_{n-1}\\
		r[r_1 \mid \cdots \mid r_n]r' &\longmapsto rr_1[r_2 \mid \cdots \mid r_n]r'\\
		&+ \sum_{i=1}^n r[r_1 \mid \cdots \mid r_{i} r_{i+1} \mid \cdots \mid r_n]r'\\
		&+ r[r_1 \mid \cdots \mid r_{n-1}]r_n r'
		\end{align*}
	\end{defn}
In the $n = 0$ case we have $B_n = B_0 = R^e$ and $\partial_0(r[r_1]r') = rr_1 \otimes r' - r \otimes r_1 r'$. The collection $(\partial_\bullet, B_\bullet)$ along with an additional $R^e$-linear map $\epsilon: B_0 = R^e \lto R, \epsilon (r \otimes r') = rr'$ is a resolution of $R$. In particular, for all $n \geq 0$ we have $\partial_{n}\partial_{n+1} = 0$.

Now, assume we are given an $R$-$R$-bimodule $M$. This is a \emph{right} $R^e$-module via the multiplication (with obvious notation) $m(r \otimes r') := r' m r$. Thus, we can tensor (over $A$) the entire resolution by $M$ and obtain a chain complex
\begin{equation}
	\ldots \stackrel{\operatorname{id}_{M} \otimes \partial_2}{\lto} M \otimes_{R^e}B_{2} \stackrel{\operatorname{id}_{M} \otimes \partial_1}{\lto} M \otimes_{R^e}B_1 \stackrel{\operatorname{id}_{M} \otimes \partial_0}{\lto} M \otimes_{R^e} B_0 \lto 0
	\end{equation}
As previously mentioned, $M$ is also a \emph{left} $R^e$-module via the multiplication $(r \otimes r')m = r m r'$. Thus, each $M \otimes B_n$ for $n \geq 0$ is a left $R^e$-module.

Similarly, considering all algebras of $R^e$-linear maps induces a cochain complex
\begin{equation}
	0 \lto \operatorname{Hom}(B_0, M) \stackrel{\und{0.2} \circ \partial_0}{\lto} \operatorname{Hom}(B_1, M)\stackrel{\und{0.2} \circ \partial_1}{\lto} \operatorname{Hom}(B_2, M) \stackrel{\und{0.2} \circ \partial_2}{\lto} \ldots
	\end{equation}
Taking homology and cohomology, we obtain the \textbf{Hochschild homology and cohomology groups}, which indeed are left $R^e$-modules.
\begin{equation}
	H_0(R,M) := H_0(M \otimes_{R^e} B_\bullet)\qquad H^0(R,M) := H^0(\operatorname{Hom}_{R^e}(B_\bullet, M))
	\end{equation}
\begin{example}
	Consider $m \in M, r,r_1,r' \in R$. The map $\operatorname{id}_M \otimes \partial_1: M \otimes B_1 \lto M \otimes B_0 = M \otimes_{R^e} R^e = M$ is the given by the following calculation
	\begin{align*}
		(\operatorname{id}_M \otimes \partial_1)(m \otimes r[r_1]r') &= m \otimes (rr_1 \otimes r') - m \otimes ( r \otimes r_1r')\\
		&= rr_1 m r' - r m r_1 r'
		\end{align*}
	Thus $H_0(R, M) = M /\{ rm - mr \mid m \in m, r \in R \}$. So in the case where $R$ is commutative, we have $H_0(R,M) = M$.
	
	Similarly, if $H^0(R,M) = \operatorname{Hom}_{R^e}(R^e, M) = \{ m \in M \mid rm = mr,  \forall r \in R \}$.
	\end{example}

\begin{defn}
	We define a map and then show that it is well defined.
	\begin{align*}
		\rho_M^n: H^n(R,M) \otimes_{R^e} H_n(R, R) &\lto H_0(R,M) = M \otimes_{R^e} R\\
		[f] \otimes [r \otimes x] &\longmapsto f(x) \otimes r
		\end{align*}
	\end{defn}
Let $g \in \operatorname{im}(\und{0.2} \circ \partial_{n-1})$ and $x \in \operatorname{im}(\partial_{n})$. Then $\rho_M^n([g] \otimes [1 \otimes x]) = g(x) \otimes 1 = (g' \partial_{n-1})(\partial_n(x')) \otimes 1$ for some $g': B_{n-1} \lto M$ and some $x' \in B_{n+1}$. This is zero as $\partial_{n-1}\partial_n = 0$.









\begin{thebibliography}{99}
	\bibitem{Friedrich} T. Friedrich, \emph{Dirac Operators in Riemannian Geometry} 20MathematicsSubjectClasification.Primary58Jx; Secondary 53C27, 53C28, 57R57, 58J05, 58J20, 58J50, 81R25.
	
	\bibitem{Hitchcock} R. Hitchcock. \emph{Differentiation, Division and the Bicategory of Landau-Ginzburg Models}. Master's thesis. \url{http://therisingsea.org/notes/MScThesisRohanHitchcock.pdf}
	\end{thebibliography}

\end{document}